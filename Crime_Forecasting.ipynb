{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe98263a",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:18.979127Z",
          "iopub.status.busy": "2024-08-08T08:15:18.978670Z",
          "iopub.status.idle": "2024-08-08T08:15:19.947699Z",
          "shell.execute_reply": "2024-08-08T08:15:19.946039Z"
        },
        "papermill": {
          "duration": 0.990509,
          "end_time": "2024-08-08T08:15:19.950294",
          "exception": false,
          "start_time": "2024-08-08T08:15:18.959785",
          "status": "completed"
        },
        "tags": [],
        "id": "fe98263a",
        "outputId": "7acf259e-07f5-4c8c-e743-a57fe0112e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/crime-cast-forecasting-crime-categories/sample.csv\n",
            "/kaggle/input/crime-cast-forecasting-crime-categories/train.csv\n",
            "/kaggle/input/crime-cast-forecasting-crime-categories/test.csv\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8653a168",
      "metadata": {
        "papermill": {
          "duration": 0.016824,
          "end_time": "2024-08-08T08:15:19.985115",
          "exception": false,
          "start_time": "2024-08-08T08:15:19.968291",
          "status": "completed"
        },
        "tags": [],
        "id": "8653a168"
      },
      "source": [
        "<h1 style=\"color:purple;\">Crime Category Prediction Challenge</h1>\n",
        "\n",
        "## Introduction\n",
        "This project aims to develop predictive models capable of accurately predicting crime categories based on various attributes related to criminal activities. The dataset provides a comprehensive snapshot of criminal activities within the city, including details such as incident locations, victim demographics, and more. By leveraging machine learning techniques, the goal is to enhance law enforcement strategies and bolster public safety measures.\n",
        "\n",
        "## Dataset Description\n",
        "The dataset consists of the following files:\n",
        "- **train.csv**: The training set, inclusive of the target variable 'crime_category' and relevant feature attributes.\n",
        "  - Shape: (20000, 22)\n",
        "- **test.csv**: The test set, containing similar feature attributes but excluding the target variable 'crime_category'.\n",
        "  - Shape: (5000, 21)\n",
        "- **sample_submission.csv**: A sample submission file provided in the correct format for competition submissions.\n",
        "\n",
        "### Features in the Dataset\n",
        "- **Location**: Street address of the crime incident.\n",
        "- **Cross_Street**: Cross street of the rounded address.\n",
        "- **Latitude**: Latitude coordinates of the crime incident.\n",
        "- **Longitude**: Longitude coordinates of the crime incident.\n",
        "- **Date_Reported**: Date the incident was reported.\n",
        "- **Date_Occurred**: Date the incident occurred.\n",
        "- **Time_Occurred**: Time the incident occurred in 24-hour military time.\n",
        "- **Area_ID**: LAPD's Geographic Area number.\n",
        "- **Area_Name**: Name designation of the LAPD Geographic Area.\n",
        "- **Reporting_District_no**: Reporting district number.\n",
        "- **Part 1-2**: Crime classification.\n",
        "- **Modus_Operandi**: Activities associated with the suspect.\n",
        "- **Victim_Age**: Age of the victim.\n",
        "- **Victim_Sex**: Gender of the victim.\n",
        "- **Victim_Descent**: Descent code of the victim.\n",
        "- **Premise_Code**: Premise code indicating the location of the crime.\n",
        "- **Premise_Description**: Description of the premise code.\n",
        "- **Weapon_Used_Code**: Weapon code indicating the type of weapon used.\n",
        "- **Weapon_Description**: Description of the weapon code.\n",
        "- **Status**: Status of the case.\n",
        "- **Status_Description**: Description of the status code.\n",
        "- **Crime_Category**: The category of the crime (Target Variable, only in train.csv)\n",
        "\n",
        "## Libraries Used\n",
        "The following libraries were utilized in this project:\n",
        "- **NumPy**: For numerical operations and handling arrays.\n",
        "- **Pandas**: For data manipulation and analysis.\n",
        "- **Scikit-learn**: For machine learning algorithms and model evaluation.\n",
        "- **XGBoost**: For gradient boosting algorithms.\n",
        "- **LightGBM**: For gradient boosting algorithms.\n",
        "- **Imblearn**: For handling imbalanced datasets.\n",
        "- **SciPy**: For scientific computations.\n",
        "- **Seaborn**: For statistical data visualization.\n",
        "- **Matplotlib**: For plotting and data visualization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb666ed",
      "metadata": {
        "papermill": {
          "duration": 0.016926,
          "end_time": "2024-08-08T08:15:20.019787",
          "exception": false,
          "start_time": "2024-08-08T08:15:20.002861",
          "status": "completed"
        },
        "tags": [],
        "id": "8eb666ed"
      },
      "source": [
        "<h2 style=\"color:purple;\">Required Libraries Import</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c02e98c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:20.061723Z",
          "iopub.status.busy": "2024-08-08T08:15:20.060711Z",
          "iopub.status.idle": "2024-08-08T08:15:20.066830Z",
          "shell.execute_reply": "2024-08-08T08:15:20.065585Z"
        },
        "papermill": {
          "duration": 0.029571,
          "end_time": "2024-08-08T08:15:20.069215",
          "exception": false,
          "start_time": "2024-08-08T08:15:20.039644",
          "status": "completed"
        },
        "tags": [],
        "id": "3c02e98c"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d8c4d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:20.105614Z",
          "iopub.status.busy": "2024-08-08T08:15:20.105134Z",
          "iopub.status.idle": "2024-08-08T08:15:23.697207Z",
          "shell.execute_reply": "2024-08-08T08:15:23.695871Z"
        },
        "papermill": {
          "duration": 3.6136,
          "end_time": "2024-08-08T08:15:23.699893",
          "exception": false,
          "start_time": "2024-08-08T08:15:20.086293",
          "status": "completed"
        },
        "tags": [],
        "id": "50d8c4d0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import xgboost as xgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import lightgbm as lgb\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8975f32f",
      "metadata": {
        "papermill": {
          "duration": 0.0175,
          "end_time": "2024-08-08T08:15:23.735311",
          "exception": false,
          "start_time": "2024-08-08T08:15:23.717811",
          "status": "completed"
        },
        "tags": [],
        "id": "8975f32f"
      },
      "source": [
        "<h2 style=\"color:purple;\">Data Loading And Data Exploration</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbce2802",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:23.771440Z",
          "iopub.status.busy": "2024-08-08T08:15:23.770816Z",
          "iopub.status.idle": "2024-08-08T08:15:24.003868Z",
          "shell.execute_reply": "2024-08-08T08:15:24.002398Z"
        },
        "papermill": {
          "duration": 0.255194,
          "end_time": "2024-08-08T08:15:24.007590",
          "exception": false,
          "start_time": "2024-08-08T08:15:23.752396",
          "status": "completed"
        },
        "tags": [],
        "id": "cbce2802"
      },
      "outputs": [],
      "source": [
        "#load the train data\n",
        "train_df = pd.read_csv(\"/kaggle/input/crime-cast-forecasting-crime-categories/train.csv\")\n",
        "# Load the test data from the specified CSV file\n",
        "test_df = pd.read_csv('/kaggle/input/crime-cast-forecasting-crime-categories/test.csv')\n",
        "# Clean column names to remove spaces for all datasets\n",
        "test_df.columns = test_df.columns.str.replace(' ', '')\n",
        "train_df.columns = train_df.columns.str.replace(' ', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f682b87",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.056692Z",
          "iopub.status.busy": "2024-08-08T08:15:24.055977Z",
          "iopub.status.idle": "2024-08-08T08:15:24.104100Z",
          "shell.execute_reply": "2024-08-08T08:15:24.102738Z"
        },
        "papermill": {
          "duration": 0.076071,
          "end_time": "2024-08-08T08:15:24.107695",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.031624",
          "status": "completed"
        },
        "tags": [],
        "id": "5f682b87",
        "outputId": "b0c13526-a925-4881-8f3d-238311c43296"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Cross_Street</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Date_Reported</th>\n",
              "      <th>Date_Occurred</th>\n",
              "      <th>Time_Occurred</th>\n",
              "      <th>Area_ID</th>\n",
              "      <th>Area_Name</th>\n",
              "      <th>Reporting_District_no</th>\n",
              "      <th>...</th>\n",
              "      <th>Victim_Age</th>\n",
              "      <th>Victim_Sex</th>\n",
              "      <th>Victim_Descent</th>\n",
              "      <th>Premise_Code</th>\n",
              "      <th>Premise_Description</th>\n",
              "      <th>Weapon_Used_Code</th>\n",
              "      <th>Weapon_Description</th>\n",
              "      <th>Status</th>\n",
              "      <th>Status_Description</th>\n",
              "      <th>Crime_Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4500    CARPENTER                    AV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.1522</td>\n",
              "      <td>-118.3910</td>\n",
              "      <td>03/09/2020 12:00:00 AM</td>\n",
              "      <td>03/06/2020 12:00:00 AM</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>N Hollywood</td>\n",
              "      <td>1563.0</td>\n",
              "      <td>...</td>\n",
              "      <td>75.0</td>\n",
              "      <td>M</td>\n",
              "      <td>W</td>\n",
              "      <td>101.0</td>\n",
              "      <td>STREET</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "      <td>Property Crimes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45TH                         ST</td>\n",
              "      <td>ALAMEDA                      ST</td>\n",
              "      <td>34.0028</td>\n",
              "      <td>-118.2391</td>\n",
              "      <td>02/27/2020 12:00:00 AM</td>\n",
              "      <td>02/27/2020 12:00:00 AM</td>\n",
              "      <td>1345.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Newton</td>\n",
              "      <td>1367.0</td>\n",
              "      <td>...</td>\n",
              "      <td>41.0</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>216.0</td>\n",
              "      <td>SWAP MEET</td>\n",
              "      <td>400.0</td>\n",
              "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "      <td>Property Crimes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>600 E  MARTIN LUTHER KING JR        BL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0111</td>\n",
              "      <td>-118.2653</td>\n",
              "      <td>08/21/2020 12:00:00 AM</td>\n",
              "      <td>08/21/2020 12:00:00 AM</td>\n",
              "      <td>605.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Newton</td>\n",
              "      <td>1343.0</td>\n",
              "      <td>...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>M</td>\n",
              "      <td>B</td>\n",
              "      <td>501.0</td>\n",
              "      <td>SINGLE FAMILY DWELLING</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "      <td>Property Crimes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14900    ORO GRANDE                   ST</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.2953</td>\n",
              "      <td>-118.4590</td>\n",
              "      <td>11/08/2020 12:00:00 AM</td>\n",
              "      <td>11/06/2020 12:00:00 AM</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Mission</td>\n",
              "      <td>1924.0</td>\n",
              "      <td>...</td>\n",
              "      <td>61.0</td>\n",
              "      <td>M</td>\n",
              "      <td>H</td>\n",
              "      <td>101.0</td>\n",
              "      <td>STREET</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "      <td>Property Crimes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7100 S  VERMONT                      AV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.9787</td>\n",
              "      <td>-118.2918</td>\n",
              "      <td>02/25/2020 12:00:00 AM</td>\n",
              "      <td>02/25/2020 12:00:00 AM</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>77th Street</td>\n",
              "      <td>1245.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>X</td>\n",
              "      <td>X</td>\n",
              "      <td>401.0</td>\n",
              "      <td>MINI-MART</td>\n",
              "      <td>400.0</td>\n",
              "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "      <td>Property Crimes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Location                     Cross_Street  \\\n",
              "0   4500    CARPENTER                    AV                              NaN   \n",
              "1           45TH                         ST  ALAMEDA                      ST   \n",
              "2    600 E  MARTIN LUTHER KING JR        BL                              NaN   \n",
              "3  14900    ORO GRANDE                   ST                              NaN   \n",
              "4   7100 S  VERMONT                      AV                              NaN   \n",
              "\n",
              "   Latitude  Longitude           Date_Reported           Date_Occurred  \\\n",
              "0   34.1522  -118.3910  03/09/2020 12:00:00 AM  03/06/2020 12:00:00 AM   \n",
              "1   34.0028  -118.2391  02/27/2020 12:00:00 AM  02/27/2020 12:00:00 AM   \n",
              "2   34.0111  -118.2653  08/21/2020 12:00:00 AM  08/21/2020 12:00:00 AM   \n",
              "3   34.2953  -118.4590  11/08/2020 12:00:00 AM  11/06/2020 12:00:00 AM   \n",
              "4   33.9787  -118.2918  02/25/2020 12:00:00 AM  02/25/2020 12:00:00 AM   \n",
              "\n",
              "   Time_Occurred  Area_ID    Area_Name  Reporting_District_no  ...  \\\n",
              "0         1800.0     15.0  N Hollywood                 1563.0  ...   \n",
              "1         1345.0     13.0       Newton                 1367.0  ...   \n",
              "2          605.0     13.0       Newton                 1343.0  ...   \n",
              "3         1800.0     19.0      Mission                 1924.0  ...   \n",
              "4         1130.0     12.0  77th Street                 1245.0  ...   \n",
              "\n",
              "   Victim_Age Victim_Sex  Victim_Descent Premise_Code     Premise_Description  \\\n",
              "0        75.0          M               W        101.0                  STREET   \n",
              "1        41.0          M               H        216.0               SWAP MEET   \n",
              "2        67.0          M               B        501.0  SINGLE FAMILY DWELLING   \n",
              "3        61.0          M               H        101.0                  STREET   \n",
              "4         0.0          X               X        401.0               MINI-MART   \n",
              "\n",
              "   Weapon_Used_Code                              Weapon_Description  Status  \\\n",
              "0               NaN                                             NaN      IC   \n",
              "1             400.0  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)      IC   \n",
              "2               NaN                                             NaN      IC   \n",
              "3               NaN                                             NaN      IC   \n",
              "4             400.0  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)      IC   \n",
              "\n",
              "  Status_Description   Crime_Category  \n",
              "0        Invest Cont  Property Crimes  \n",
              "1        Invest Cont  Property Crimes  \n",
              "2        Invest Cont  Property Crimes  \n",
              "3        Invest Cont  Property Crimes  \n",
              "4        Invest Cont  Property Crimes  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#exploring some rows of data\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e8bc3b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.156379Z",
          "iopub.status.busy": "2024-08-08T08:15:24.155393Z",
          "iopub.status.idle": "2024-08-08T08:15:24.162822Z",
          "shell.execute_reply": "2024-08-08T08:15:24.161644Z"
        },
        "papermill": {
          "duration": 0.036832,
          "end_time": "2024-08-08T08:15:24.165778",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.128946",
          "status": "completed"
        },
        "tags": [],
        "id": "70e8bc3b",
        "outputId": "8bd78ce9-d7e4-4c3d-9cb2-d63512a26a84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20000, 22)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking the shape of the train data\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77d531f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.208231Z",
          "iopub.status.busy": "2024-08-08T08:15:24.207128Z",
          "iopub.status.idle": "2024-08-08T08:15:24.244534Z",
          "shell.execute_reply": "2024-08-08T08:15:24.243181Z"
        },
        "papermill": {
          "duration": 0.059079,
          "end_time": "2024-08-08T08:15:24.246970",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.187891",
          "status": "completed"
        },
        "tags": [],
        "id": "c77d531f",
        "outputId": "87e21d75-d6f6-4681-fff1-4669a120d0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 22 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Location               20000 non-null  object \n",
            " 1   Cross_Street           3448 non-null   object \n",
            " 2   Latitude               20000 non-null  float64\n",
            " 3   Longitude              20000 non-null  float64\n",
            " 4   Date_Reported          20000 non-null  object \n",
            " 5   Date_Occurred          20000 non-null  object \n",
            " 6   Time_Occurred          20000 non-null  float64\n",
            " 7   Area_ID                20000 non-null  float64\n",
            " 8   Area_Name              20000 non-null  object \n",
            " 9   Reporting_District_no  20000 non-null  float64\n",
            " 10  Part1-2                20000 non-null  float64\n",
            " 11  Modus_Operandi         17259 non-null  object \n",
            " 12  Victim_Age             20000 non-null  float64\n",
            " 13  Victim_Sex             17376 non-null  object \n",
            " 14  Victim_Descent         17376 non-null  object \n",
            " 15  Premise_Code           20000 non-null  float64\n",
            " 16  Premise_Description    19995 non-null  object \n",
            " 17  Weapon_Used_Code       7335 non-null   float64\n",
            " 18  Weapon_Description     7335 non-null   object \n",
            " 19  Status                 20000 non-null  object \n",
            " 20  Status_Description     20000 non-null  object \n",
            " 21  Crime_Category         20000 non-null  object \n",
            "dtypes: float64(9), object(13)\n",
            "memory usage: 3.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Print concise summary of the DataFrame including column names, non-null values, and data types\n",
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bad27e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.284605Z",
          "iopub.status.busy": "2024-08-08T08:15:24.284203Z",
          "iopub.status.idle": "2024-08-08T08:15:24.306160Z",
          "shell.execute_reply": "2024-08-08T08:15:24.303474Z"
        },
        "papermill": {
          "duration": 0.044246,
          "end_time": "2024-08-08T08:15:24.309301",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.265055",
          "status": "completed"
        },
        "tags": [],
        "id": "24bad27e",
        "outputId": "ec633278-1ca6-4e97-b170-828b345fc96a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Location                     0\n",
            "Cross_Street             16552\n",
            "Latitude                     0\n",
            "Longitude                    0\n",
            "Date_Reported                0\n",
            "Date_Occurred                0\n",
            "Time_Occurred                0\n",
            "Area_ID                      0\n",
            "Area_Name                    0\n",
            "Reporting_District_no        0\n",
            "Part1-2                      0\n",
            "Modus_Operandi            2741\n",
            "Victim_Age                   0\n",
            "Victim_Sex                2624\n",
            "Victim_Descent            2624\n",
            "Premise_Code                 0\n",
            "Premise_Description          5\n",
            "Weapon_Used_Code         12665\n",
            "Weapon_Description       12665\n",
            "Status                       0\n",
            "Status_Description           0\n",
            "Crime_Category               0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# getting column wise count of null values\n",
        "print(train_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8878667",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.351676Z",
          "iopub.status.busy": "2024-08-08T08:15:24.351234Z",
          "iopub.status.idle": "2024-08-08T08:15:24.378750Z",
          "shell.execute_reply": "2024-08-08T08:15:24.377427Z"
        },
        "papermill": {
          "duration": 0.050519,
          "end_time": "2024-08-08T08:15:24.381204",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.330685",
          "status": "completed"
        },
        "tags": [],
        "id": "d8878667",
        "outputId": "7ad82f72-26cc-4a49-d32e-f5750f54e9c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Cross_Street</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Date_Reported</th>\n",
              "      <th>Date_Occurred</th>\n",
              "      <th>Time_Occurred</th>\n",
              "      <th>Area_ID</th>\n",
              "      <th>Area_Name</th>\n",
              "      <th>Reporting_District_no</th>\n",
              "      <th>...</th>\n",
              "      <th>Modus_Operandi</th>\n",
              "      <th>Victim_Age</th>\n",
              "      <th>Victim_Sex</th>\n",
              "      <th>Victim_Descent</th>\n",
              "      <th>Premise_Code</th>\n",
              "      <th>Premise_Description</th>\n",
              "      <th>Weapon_Used_Code</th>\n",
              "      <th>Weapon_Description</th>\n",
              "      <th>Status</th>\n",
              "      <th>Status_Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1500    LEIGHTON                     AV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0128</td>\n",
              "      <td>-118.3045</td>\n",
              "      <td>03/03/2020 12:00:00 AM</td>\n",
              "      <td>03/03/2020 12:00:00 AM</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Southwest</td>\n",
              "      <td>376.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0416 1241 1243 1813 1821 2000</td>\n",
              "      <td>28.0</td>\n",
              "      <td>F</td>\n",
              "      <td>H</td>\n",
              "      <td>501.0</td>\n",
              "      <td>SINGLE FAMILY DWELLING</td>\n",
              "      <td>400.0</td>\n",
              "      <td>STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100 S  NORMANDIE                    AV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0726</td>\n",
              "      <td>-118.3029</td>\n",
              "      <td>06/01/2020 12:00:00 AM</td>\n",
              "      <td>04/25/2020 12:00:00 AM</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Olympic</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0344 0394</td>\n",
              "      <td>26.0</td>\n",
              "      <td>M</td>\n",
              "      <td>B</td>\n",
              "      <td>502.0</td>\n",
              "      <td>MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300 E  111TH                        ST</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.9348</td>\n",
              "      <td>-118.2695</td>\n",
              "      <td>08/28/2020 12:00:00 AM</td>\n",
              "      <td>08/27/2020 12:00:00 AM</td>\n",
              "      <td>900.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Southeast</td>\n",
              "      <td>1844.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1822 0701 1914 0355 1202 0100</td>\n",
              "      <td>62.0</td>\n",
              "      <td>F</td>\n",
              "      <td>B</td>\n",
              "      <td>721.0</td>\n",
              "      <td>HIGH SCHOOL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1300 S  LA BREA                      AV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0497</td>\n",
              "      <td>-118.3442</td>\n",
              "      <td>12/23/2020 12:00:00 AM</td>\n",
              "      <td>12/03/2020 12:00:00 AM</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Wilshire</td>\n",
              "      <td>765.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>108.0</td>\n",
              "      <td>PARKING LOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IC</td>\n",
              "      <td>Invest Cont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11000    MORRISON                     ST</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.1611</td>\n",
              "      <td>-118.3704</td>\n",
              "      <td>08/30/2020 12:00:00 AM</td>\n",
              "      <td>08/29/2020 12:00:00 AM</td>\n",
              "      <td>130.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>N Hollywood</td>\n",
              "      <td>1555.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1501</td>\n",
              "      <td>37.0</td>\n",
              "      <td>F</td>\n",
              "      <td>W</td>\n",
              "      <td>501.0</td>\n",
              "      <td>SINGLE FAMILY DWELLING</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AO</td>\n",
              "      <td>Adult Other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Location Cross_Street  Latitude  Longitude  \\\n",
              "0   1500    LEIGHTON                     AV          NaN   34.0128  -118.3045   \n",
              "1    100 S  NORMANDIE                    AV          NaN   34.0726  -118.3029   \n",
              "2    300 E  111TH                        ST          NaN   33.9348  -118.2695   \n",
              "3   1300 S  LA BREA                      AV          NaN   34.0497  -118.3442   \n",
              "4  11000    MORRISON                     ST          NaN   34.1611  -118.3704   \n",
              "\n",
              "            Date_Reported           Date_Occurred  Time_Occurred  Area_ID  \\\n",
              "0  03/03/2020 12:00:00 AM  03/03/2020 12:00:00 AM         2000.0      3.0   \n",
              "1  06/01/2020 12:00:00 AM  04/25/2020 12:00:00 AM         1700.0     20.0   \n",
              "2  08/28/2020 12:00:00 AM  08/27/2020 12:00:00 AM          900.0     18.0   \n",
              "3  12/23/2020 12:00:00 AM  12/03/2020 12:00:00 AM         2200.0      7.0   \n",
              "4  08/30/2020 12:00:00 AM  08/29/2020 12:00:00 AM          130.0     15.0   \n",
              "\n",
              "     Area_Name  Reporting_District_no  ...                 Modus_Operandi  \\\n",
              "0    Southwest                  376.0  ...  0416 1241 1243 1813 1821 2000   \n",
              "1      Olympic                 2014.0  ...                      0344 0394   \n",
              "2    Southeast                 1844.0  ...  1822 0701 1914 0355 1202 0100   \n",
              "3     Wilshire                  765.0  ...                            NaN   \n",
              "4  N Hollywood                 1555.0  ...                           1501   \n",
              "\n",
              "  Victim_Age  Victim_Sex Victim_Descent Premise_Code  \\\n",
              "0       28.0           F              H        501.0   \n",
              "1       26.0           M              B        502.0   \n",
              "2       62.0           F              B        721.0   \n",
              "3        0.0         NaN            NaN        108.0   \n",
              "4       37.0           F              W        501.0   \n",
              "\n",
              "                            Premise_Description Weapon_Used_Code  \\\n",
              "0                        SINGLE FAMILY DWELLING            400.0   \n",
              "1  MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)              NaN   \n",
              "2                                   HIGH SCHOOL              NaN   \n",
              "3                                   PARKING LOT              NaN   \n",
              "4                        SINGLE FAMILY DWELLING              NaN   \n",
              "\n",
              "                               Weapon_Description Status Status_Description  \n",
              "0  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)     IC        Invest Cont  \n",
              "1                                             NaN     IC        Invest Cont  \n",
              "2                                             NaN     IC        Invest Cont  \n",
              "3                                             NaN     IC        Invest Cont  \n",
              "4                                             NaN     AO        Adult Other  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#explore the first few rows of test data\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f206400c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.421500Z",
          "iopub.status.busy": "2024-08-08T08:15:24.421072Z",
          "iopub.status.idle": "2024-08-08T08:15:24.428321Z",
          "shell.execute_reply": "2024-08-08T08:15:24.427062Z"
        },
        "papermill": {
          "duration": 0.029224,
          "end_time": "2024-08-08T08:15:24.430814",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.401590",
          "status": "completed"
        },
        "tags": [],
        "id": "f206400c",
        "outputId": "2eb4a5bb-2fad-40f8-eac7-646d306a9224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 21)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking the shape of the test data\n",
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a60a4dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.470320Z",
          "iopub.status.busy": "2024-08-08T08:15:24.469863Z",
          "iopub.status.idle": "2024-08-08T08:15:24.485296Z",
          "shell.execute_reply": "2024-08-08T08:15:24.484181Z"
        },
        "papermill": {
          "duration": 0.038136,
          "end_time": "2024-08-08T08:15:24.487714",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.449578",
          "status": "completed"
        },
        "tags": [],
        "id": "7a60a4dc",
        "outputId": "0a168602-bfe9-4058-bd76-38668bbdf537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 21 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Location               5000 non-null   object \n",
            " 1   Cross_Street           810 non-null    object \n",
            " 2   Latitude               5000 non-null   float64\n",
            " 3   Longitude              5000 non-null   float64\n",
            " 4   Date_Reported          5000 non-null   object \n",
            " 5   Date_Occurred          5000 non-null   object \n",
            " 6   Time_Occurred          5000 non-null   float64\n",
            " 7   Area_ID                5000 non-null   float64\n",
            " 8   Area_Name              5000 non-null   object \n",
            " 9   Reporting_District_no  5000 non-null   float64\n",
            " 10  Part1-2                5000 non-null   float64\n",
            " 11  Modus_Operandi         4316 non-null   object \n",
            " 12  Victim_Age             5000 non-null   float64\n",
            " 13  Victim_Sex             4357 non-null   object \n",
            " 14  Victim_Descent         4357 non-null   object \n",
            " 15  Premise_Code           5000 non-null   float64\n",
            " 16  Premise_Description    4999 non-null   object \n",
            " 17  Weapon_Used_Code       1847 non-null   float64\n",
            " 18  Weapon_Description     1847 non-null   object \n",
            " 19  Status                 5000 non-null   object \n",
            " 20  Status_Description     5000 non-null   object \n",
            "dtypes: float64(9), object(12)\n",
            "memory usage: 820.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Print concise summary of the test DataFrame including column names, non-null values, and data types\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89f6da6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.526104Z",
          "iopub.status.busy": "2024-08-08T08:15:24.525703Z",
          "iopub.status.idle": "2024-08-08T08:15:24.536132Z",
          "shell.execute_reply": "2024-08-08T08:15:24.535020Z"
        },
        "papermill": {
          "duration": 0.032269,
          "end_time": "2024-08-08T08:15:24.538375",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.506106",
          "status": "completed"
        },
        "tags": [],
        "id": "89f6da6f",
        "outputId": "871ab244-7353-4ede-9238-b228723c15cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Location                    0\n",
            "Cross_Street             4190\n",
            "Latitude                    0\n",
            "Longitude                   0\n",
            "Date_Reported               0\n",
            "Date_Occurred               0\n",
            "Time_Occurred               0\n",
            "Area_ID                     0\n",
            "Area_Name                   0\n",
            "Reporting_District_no       0\n",
            "Part1-2                     0\n",
            "Modus_Operandi            684\n",
            "Victim_Age                  0\n",
            "Victim_Sex                643\n",
            "Victim_Descent            643\n",
            "Premise_Code                0\n",
            "Premise_Description         1\n",
            "Weapon_Used_Code         3153\n",
            "Weapon_Description       3153\n",
            "Status                      0\n",
            "Status_Description          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# getting column wise count of null values\n",
        "print(test_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff710826",
      "metadata": {
        "papermill": {
          "duration": 0.019246,
          "end_time": "2024-08-08T08:15:24.575961",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.556715",
          "status": "completed"
        },
        "tags": [],
        "id": "ff710826"
      },
      "source": [
        "<h2 style=\"color:purple;\">Feature Engineering</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c1cfe5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.614711Z",
          "iopub.status.busy": "2024-08-08T08:15:24.614288Z",
          "iopub.status.idle": "2024-08-08T08:15:24.900777Z",
          "shell.execute_reply": "2024-08-08T08:15:24.899352Z"
        },
        "papermill": {
          "duration": 0.308782,
          "end_time": "2024-08-08T08:15:24.903459",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.594677",
          "status": "completed"
        },
        "tags": [],
        "id": "f1c1cfe5"
      },
      "outputs": [],
      "source": [
        "#feature engineering function to deal with the formats of columns.\n",
        "def feature_engineering(df):\n",
        "    date_cols = ['Date_Reported', 'Date_Occurred']\n",
        "\n",
        "    for date_col in date_cols:\n",
        "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "        df[f'{date_col}_Year'] = df[date_col].dt.year\n",
        "        df[f'{date_col}_Month'] = df[date_col].dt.month\n",
        "        df[f'{date_col}_Day'] = df[date_col].dt.day\n",
        "\n",
        "    df = df.drop(columns=date_cols)\n",
        "    return df\n",
        "train_df = feature_engineering(train_df)\n",
        "test_df = feature_engineering(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e0b651a",
      "metadata": {
        "papermill": {
          "duration": 0.018592,
          "end_time": "2024-08-08T08:15:24.940259",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.921667",
          "status": "completed"
        },
        "tags": [],
        "id": "6e0b651a"
      },
      "source": [
        "<h2 style=\"color:purple;\">Distribution of Target Variable</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4488a6e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:24.978954Z",
          "iopub.status.busy": "2024-08-08T08:15:24.978524Z",
          "iopub.status.idle": "2024-08-08T08:15:24.986141Z",
          "shell.execute_reply": "2024-08-08T08:15:24.984724Z"
        },
        "papermill": {
          "duration": 0.030071,
          "end_time": "2024-08-08T08:15:24.988764",
          "exception": false,
          "start_time": "2024-08-08T08:15:24.958693",
          "status": "completed"
        },
        "tags": [],
        "id": "d4488a6e",
        "outputId": "6c08e840-6d65-4d49-efa4-dc4cec0f633f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Plot a count plot for the 'Crime_Category' column to show the frequency of each category\\nsns.countplot(x='Crime_Category', data=train_df)\\n# Rotate the x-axis labels by 90 degrees for better readability\\nplt.xticks(rotation=90)\\nplt.show()\\n\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Plot a count plot for the 'Crime_Category' column to show the frequency of each category\n",
        "sns.countplot(x='Crime_Category', data=train_df)\n",
        "# Rotate the x-axis labels by 90 degrees for better readability\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfeddb1",
      "metadata": {
        "papermill": {
          "duration": 0.018619,
          "end_time": "2024-08-08T08:15:25.089268",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.070649",
          "status": "completed"
        },
        "tags": [],
        "id": "5cfeddb1"
      },
      "source": [
        "**As we can see, the classes are imbalanced for target column. We will use some sampling techniques to deal with this imbalance and check if these techniques improve the accuracy further after fitting the models without these techniques being applied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d923c0f0",
      "metadata": {
        "papermill": {
          "duration": 0.019164,
          "end_time": "2024-08-08T08:15:25.127339",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.108175",
          "status": "completed"
        },
        "tags": [],
        "id": "d923c0f0"
      },
      "source": [
        "<h2 style=\"color:purple;\">Exploratory Data Analysis</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395ec1a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.170623Z",
          "iopub.status.busy": "2024-08-08T08:15:25.170171Z",
          "iopub.status.idle": "2024-08-08T08:15:25.193950Z",
          "shell.execute_reply": "2024-08-08T08:15:25.192376Z"
        },
        "papermill": {
          "duration": 0.047945,
          "end_time": "2024-08-08T08:15:25.196718",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.148773",
          "status": "completed"
        },
        "tags": [],
        "id": "395ec1a0",
        "outputId": "daaefdca-4b15-4a17-9144-7445290ac22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numerical columns: ['Latitude', 'Longitude', 'Time_Occurred', 'Area_ID', 'Reporting_District_no', 'Victim_Age', 'Premise_Code', 'Weapon_Used_Code']\n",
            "Categorical columns: ['Location', 'Cross_Street', 'Area_Name', 'Part1-2', 'Modus_Operandi', 'Victim_Sex', 'Victim_Descent', 'Premise_Description', 'Weapon_Description', 'Status', 'Status_Description']\n"
          ]
        }
      ],
      "source": [
        "# Define the target column\n",
        "target_col = 'Crime_Category'\n",
        "train_df['Part1-2'] = train_df['Part1-2'].astype('category')\n",
        "test_df['Part1-2'] = test_df['Part1-2'].astype('category')\n",
        "# Identify feature types\n",
        "numerical_cols = train_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_cols = train_df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "numerical_cols = [col for col in numerical_cols if col != target_col]\n",
        "categorical_cols = [col for col in categorical_cols if col != target_col]\n",
        "# Print identified columns\n",
        "print(\"Numerical columns:\", numerical_cols)\n",
        "print(\"Categorical columns:\", categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0096de66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.237820Z",
          "iopub.status.busy": "2024-08-08T08:15:25.237405Z",
          "iopub.status.idle": "2024-08-08T08:15:25.253362Z",
          "shell.execute_reply": "2024-08-08T08:15:25.252165Z"
        },
        "papermill": {
          "duration": 0.039565,
          "end_time": "2024-08-08T08:15:25.256074",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.216509",
          "status": "completed"
        },
        "tags": [],
        "id": "0096de66"
      },
      "outputs": [],
      "source": [
        "def perform_eda1(df, target_col):\n",
        "    # Summary statistics\n",
        "    print(\"Summary Statistics for Numerical Features:\")\n",
        "    print(df[numerical_cols].describe())\n",
        "    print(\"\\nSummary Statistics for Categorical Features:\")\n",
        "    print(df[categorical_cols].describe())\n",
        "def perform_eda2(df, target_col):\n",
        "    # Distribution plots for numerical features\n",
        "    n_numerical = len(numerical_cols)\n",
        "    plt.figure(figsize=(20, 5 * (n_numerical // 3 + 1)))\n",
        "    for i, col in enumerate(numerical_cols):\n",
        "        plt.subplot(n_numerical // 3 + 1, 3, i + 1)\n",
        "        sns.histplot(df[col], kde=True)\n",
        "        plt.title(f'Distribution of {col}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "def perform_eda3(df, target_col):\n",
        "    # Count plots for categorical features\n",
        "    n_categorical = len(categorical_cols)\n",
        "    plt.figure(figsize=(20, 5 * (n_categorical // 3 + 1)))\n",
        "    for i, col in enumerate(categorical_cols):\n",
        "        plt.subplot(n_categorical // 3 + 1, 3, i + 1)\n",
        "        sns.countplot(x=col, data=df)\n",
        "        plt.title(f'Count of {col}')\n",
        "        plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "def perform_eda4(df, target_col):\n",
        "    # Correlation matrix for numerical features\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    corr_matrix = df[numerical_cols].corr()\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.show()\n",
        "def perform_eda5(df, target_col):\n",
        "    # Scatter plots for numerical features against the target variable\n",
        "    n_numerical = len(numerical_cols)\n",
        "    plt.figure(figsize=(20, 5 * (n_numerical // 3 + 1)))\n",
        "    for i, col in enumerate(numerical_cols):\n",
        "        plt.subplot(n_numerical // 3 + 1, 3, i + 1)\n",
        "        sns.scatterplot(x=col, y=target_col, data=df)\n",
        "        plt.title(f'{col} vs {target_col}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "def perform_eda6(df, target_col):\n",
        "    # Count plots for categorical features against the target variable\n",
        "    n_categorical = len(categorical_cols)\n",
        "    plt.figure(figsize=(20, 5 * (n_categorical // 3 + 1)))\n",
        "    for i, col in enumerate(categorical_cols):\n",
        "        plt.subplot(n_categorical // 3 + 1, 3, i + 1)\n",
        "        sns.countplot(x=col, hue=target_col, data=df)\n",
        "        plt.title(f'{col} vs {target_col}')\n",
        "        plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f515ca4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.296447Z",
          "iopub.status.busy": "2024-08-08T08:15:25.295966Z",
          "iopub.status.idle": "2024-08-08T08:15:25.302758Z",
          "shell.execute_reply": "2024-08-08T08:15:25.301628Z"
        },
        "papermill": {
          "duration": 0.029396,
          "end_time": "2024-08-08T08:15:25.305203",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.275807",
          "status": "completed"
        },
        "tags": [],
        "id": "1f515ca4",
        "outputId": "bb6163d5-64c1-454c-daa8-18f23b6be02f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Call the function\\nperform_eda1(train_df, 'Crime_Category')\\n\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Call the function\n",
        "perform_eda1(train_df, 'Crime_Category')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d058e3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.345728Z",
          "iopub.status.busy": "2024-08-08T08:15:25.345341Z",
          "iopub.status.idle": "2024-08-08T08:15:25.352424Z",
          "shell.execute_reply": "2024-08-08T08:15:25.351016Z"
        },
        "papermill": {
          "duration": 0.030432,
          "end_time": "2024-08-08T08:15:25.354858",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.324426",
          "status": "completed"
        },
        "tags": [],
        "id": "97d058e3",
        "outputId": "1f13b212-335b-404b-9e5a-0e4f48b1d142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Distribution Of Numerical Features \\nperform_eda2(train_df, 'Crime_Category')\\n\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Distribution Of Numerical Features\n",
        "perform_eda2(train_df, 'Crime_Category')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4812f79d",
      "metadata": {
        "papermill": {
          "duration": 0.020665,
          "end_time": "2024-08-08T08:15:25.395474",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.374809",
          "status": "completed"
        },
        "tags": [],
        "id": "4812f79d"
      },
      "source": [
        "### Distribution of Numerical Features\n",
        "\n",
        "#### Distribution of Latitude\n",
        "- **Observation**: The majority of latitude values are concentrated between 34 and 35.\n",
        "- **Insight**: This suggests that most of the crimes are occurring within a narrow range of latitude, indicating a specific geographic concentration.\n",
        "\n",
        "#### Distribution of Longitude\n",
        "- **Observation**: The majority of longitude values are concentrated around -118.\n",
        "- **Insight**: Similar to latitude, this indicates that the crimes are geographically concentrated in a specific region.\n",
        "\n",
        "#### Distribution of Time_Occurred\n",
        "- **Observation**: The distribution of the time occurred is relatively uniform, with some peaks around early morning (0-600), noon (1200-1400), and late evening (1800-2400).\n",
        "- **Insight**: This could indicate that crimes occur throughout the day but have specific peaks, possibly correlating with times when people are more active or when there is less law enforcement presence.\n",
        "\n",
        "#### Distribution of Area_ID\n",
        "- **Observation**: The distribution is fairly uniform across different area IDs, with a few areas showing slightly higher crime counts.\n",
        "- **Insight**: This suggests that crimes are spread out across various geographic areas, with certain areas experiencing higher crime rates.\n",
        "\n",
        "#### Distribution of Reporting_District_no\n",
        "- **Observation**: The distribution shows a somewhat uniform spread with some fluctuations.\n",
        "- **Insight**: This indicates that the reporting of crimes is distributed across different districts, with no single district overwhelmingly reporting more crimes.\n",
        "\n",
        "#### Distribution of Victim_Age\n",
        "- **Observation**: The distribution is right-skewed, with a large number of victims being very young (age 0) and another peak around age 20-30.\n",
        "- **Insight**: This could suggest that a significant number of victims are very young (possibly indicating child-related crimes), and another large group of victims are young adults.\n",
        "\n",
        "#### Distribution of Premise_Code\n",
        "- **Observation**: There are several distinct peaks in the distribution, indicating the presence of certain types of premises where crimes are more common.\n",
        "- **Insight**: Certain premise types are more frequently associated with crimes. This information can be used to identify high-risk locations.\n",
        "\n",
        "#### Distribution of Weapon_Used_Code\n",
        "- **Observation**: The distribution shows distinct peaks at specific weapon codes.\n",
        "- **Insight**: Certain types of weapons are more commonly used in crimes. This information is crucial for law enforcement agencies as it highlights the types of weapons that are more prevalent in criminal activities. Focused efforts on controlling these specific types of weapons could potentially reduce crime rates. Additionally, this data could inform public safety campaigns and policy decisions regarding weapon regulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a5a88a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.437702Z",
          "iopub.status.busy": "2024-08-08T08:15:25.437297Z",
          "iopub.status.idle": "2024-08-08T08:15:25.444834Z",
          "shell.execute_reply": "2024-08-08T08:15:25.443648Z"
        },
        "papermill": {
          "duration": 0.032462,
          "end_time": "2024-08-08T08:15:25.447246",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.414784",
          "status": "completed"
        },
        "tags": [],
        "id": "d9a5a88a",
        "outputId": "3785a8ea-9473-4a83-a946-75e5a970dbeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Count Plots For Categorical Features \\nperform_eda3(train_df, 'Crime_Category')\\n\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Count Plots For Categorical Features\n",
        "perform_eda3(train_df, 'Crime_Category')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8fd3140",
      "metadata": {
        "papermill": {
          "duration": 0.019719,
          "end_time": "2024-08-08T08:15:25.486680",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.466961",
          "status": "completed"
        },
        "tags": [],
        "id": "f8fd3140"
      },
      "source": [
        "### Count Plots for Categorical Columns\n",
        "\n",
        "#### 1. Count of Location\n",
        "- **Observation**: The plot is highly dense and difficult to read due to the large number of unique locations.\n",
        "- **Insight**: The data contains a vast number of unique locations where crimes have occurred. This indicates that crimes are widely distributed across many different locations, which could make it challenging to target specific areas for crime prevention.\n",
        "\n",
        "#### 2. Count of Cross_Street\n",
        "- **Observation**: Similar to the \"Location\" column, the \"Cross_Street\" column also has a large number of unique values.\n",
        "- **Insight**: This suggests that crimes are spread across various cross streets, further indicating the widespread nature of criminal activities across the city.\n",
        "\n",
        "#### 3. Count of Area_Name\n",
        "- **Observation**: Some areas, like \"N Hollywood\" and \"Newton,\" have higher crime counts compared to others.\n",
        "- **Insight**: Certain areas experience more crimes than others, which could help in focusing law enforcement efforts on high-crime areas to improve safety and allocate resources more efficiently.\n",
        "\n",
        "#### 4. Count of Part1-2\n",
        "- **Observation**: The counts for Part 1 and Part 2 crimes show that Part 1 crimes are more frequent.\n",
        "- **Insight**: Part 1 crimes (likely more serious offenses) are more common than Part 2 crimes. This distinction can help in understanding the severity and type of crimes occurring in the city.\n",
        "\n",
        "#### 5. Count of Modus_Operandi\n",
        "- **Observation**: The plot is very dense and difficult to interpret due to the large number of unique values.\n",
        "- **Insight**: There is a wide variety of methods used in committing crimes, indicating the diverse nature of criminal activities. This could be useful for profiling and understanding different criminal behaviors.\n",
        "\n",
        "#### 6. Count of Victim_Sex\n",
        "- **Observation**: Males and females are the most common victims, with a small number of unknown or unspecified sexes.\n",
        "- **Insight**: Both males and females are victims of crimes, but the distribution is fairly balanced. This suggests that crime prevention efforts need to address the safety of all genders.\n",
        "\n",
        "#### 7. Count of Victim_Descent\n",
        "- **Observation**: Certain descent groups, like \"W\" (White) and \"H\" (Hispanic), have higher counts compared to others.\n",
        "- **Insight**: Specific demographic groups are more frequently victims of crimes. This information can help in tailoring community outreach and crime prevention programs to protect vulnerable populations.\n",
        "\n",
        "#### 8. Count of Premise_Description\n",
        "- **Observation**: The plot is highly dense with a large number of unique premises.\n",
        "- **Insight**: Crimes occur in a wide variety of premises, indicating that no single type of location is immune to criminal activities. This diversity necessitates a broad approach to crime prevention across different types of premises.\n",
        "\n",
        "#### 9. Count of Weapon_Description\n",
        "- **Observation**: Some weapons, like \"Strong-Arm\" are more commonly used.\n",
        "- **Insight**: Certain weapons are frequently used in crimes. Focusing on controlling these weapons could help reduce crime rates.\n",
        "\n",
        "#### 10. Count of Status\n",
        "- **Observation**: Most cases are marked as \"IC\" (Investigation Continuing).\n",
        "- **Insight**: A large number of cases remain under investigation, indicating a potential backlog in case processing or challenges in solving crimes.\n",
        "\n",
        "#### 11. Count of Status_Description\n",
        "- **Observation**: Similar to \"Status,\" most cases fall under \"Invest Cont\" (Investigation Continuing).\n",
        "- **Insight**: There is a significant proportion of cases that are still being investigated, which may point to resource constraints or complexities in solving crimes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c6e648",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.528348Z",
          "iopub.status.busy": "2024-08-08T08:15:25.527923Z",
          "iopub.status.idle": "2024-08-08T08:15:25.535683Z",
          "shell.execute_reply": "2024-08-08T08:15:25.534351Z"
        },
        "papermill": {
          "duration": 0.031851,
          "end_time": "2024-08-08T08:15:25.538255",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.506404",
          "status": "completed"
        },
        "tags": [],
        "id": "f0c6e648",
        "outputId": "f6612fa3-b808-4567-a04a-e6dede2f15da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n#Correlation matrix for Numerical Features \\nperform_eda4(train_df, 'Crime_Category')\\n\""
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#Correlation matrix for Numerical Features\n",
        "perform_eda4(train_df, 'Crime_Category')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c1cc339",
      "metadata": {
        "papermill": {
          "duration": 0.022692,
          "end_time": "2024-08-08T08:15:25.580446",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.557754",
          "status": "completed"
        },
        "tags": [],
        "id": "7c1cc339"
      },
      "source": [
        "### Correlation Matrix for Numerical Features\n",
        "\n",
        "- **Latitude and Longitude**:\n",
        "  - **Observation**: There is a strong negative correlation between latitude and longitude (-1.00).\n",
        "  - **Insight**: This is expected due to the geographic layout, as changes in latitude and longitude are inherently linked.\n",
        "\n",
        "- **Time_Occurred**:\n",
        "  - **Observation**: There are very low correlations between `Time_Occurred` and all other features.\n",
        "  - **Insight**: The time at which a crime occurs does not seem to have a strong relationship with other numerical features.\n",
        "\n",
        "- **Area_ID and Reporting_District_no**:\n",
        "  - **Observation**: These features show a perfect correlation (1.00) with each other.\n",
        "  - **Insight**: This indicates that `Area_ID` and `Reporting_District_no` might be representing the same information. One of these columns could be redundant.\n",
        "\n",
        "- **Victim_Age**:\n",
        "  - **Observation**: `Victim_Age` shows a low correlation with all other features, the highest being with `Premise_Code` (0.19).\n",
        "  - **Insight**: The age of the victim does not strongly correlate with other numerical features, suggesting that it might provide unique information.\n",
        "\n",
        "- **Premise_Code and Weapon_Used_Code**:\n",
        "  - **Observation**: There is a moderate correlation (0.20) between `Premise_Code` and `Weapon_Used_Code`.\n",
        "  - **Insight**: Certain premises might be associated with specific types of weapons used in crimes.\n",
        "\n",
        "- **Area_ID, Reporting_District_no, and Premise_Code**:\n",
        "  - **Observation**: `Area_ID` and `Reporting_District_no` have very low correlations with `Premise_Code` and other features.\n",
        "  - **Insight**: The area and district in which crimes occur do not strongly correlate with other numerical features, suggesting a more complex interplay of factors influencing crime locations.\n",
        "\n",
        "- **Weapon_Used_Code**:\n",
        "  - **Observation**: `Weapon_Used_Code` shows a moderate correlation with `Premise_Code` (0.20).\n",
        "  - **Insight**: The type of weapon used might be somewhat related to the premise where the crime occurs, indicating that certain environments may be more prone to specific types of weapon usage.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8fd592",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.624120Z",
          "iopub.status.busy": "2024-08-08T08:15:25.623076Z",
          "iopub.status.idle": "2024-08-08T08:15:25.630177Z",
          "shell.execute_reply": "2024-08-08T08:15:25.629007Z"
        },
        "papermill": {
          "duration": 0.031061,
          "end_time": "2024-08-08T08:15:25.632630",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.601569",
          "status": "completed"
        },
        "tags": [],
        "id": "8b8fd592",
        "outputId": "3b95f4e5-fb61-482b-b1b0-5a0a99290941"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n#Scatter Plots for Numerical Features against Crime_Category\\nperform_eda5(train_df, 'Crime_Category')\\n\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#Scatter Plots for Numerical Features against Crime_Category\n",
        "perform_eda5(train_df, 'Crime_Category')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47375eae",
      "metadata": {
        "papermill": {
          "duration": 0.01924,
          "end_time": "2024-08-08T08:15:25.671311",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.652071",
          "status": "completed"
        },
        "tags": [],
        "id": "47375eae"
      },
      "source": [
        "### Scatter Plots of Numerical Columns Against Crime_Category\n",
        "\n",
        "#### Latitude vs Crime_Category\n",
        "- **Observation**: Crimes are fairly evenly distributed across the range of latitude values.\n",
        "- **Insight**: There is no strong relationship between latitude and the type of crime, indicating that crime categories are spread out across different latitudes.\n",
        "\n",
        "#### Longitude vs Crime_Category\n",
        "- **Observation**: Similar to latitude, crimes are evenly distributed across the range of longitude values.\n",
        "- **Insight**: There is no strong relationship between longitude and the type of crime, suggesting that crime categories are spread out across different longitudes.\n",
        "\n",
        "#### Time_Occurred vs Crime_Category\n",
        "- **Observation**: Crimes occur at various times of the day, with no clear pattern linking specific times to crime categories.\n",
        "- **Insight**: Time of occurrence does not strongly differentiate between crime categories, indicating that crimes of all types can happen at any time.\n",
        "\n",
        "#### Area_ID vs Crime_Category\n",
        "- **Observation**: Crimes are evenly distributed across different Area_IDs.\n",
        "- **Insight**: There is no strong relationship between Area_ID and the type of crime, suggesting that crime categories are spread across various geographic areas.\n",
        "\n",
        "#### Reporting_District_no vs Crime_Category\n",
        "- **Observation**: Crimes are distributed across different reporting districts, with no clear pattern linking specific districts to crime categories.\n",
        "- **Insight**: Reporting district numbers do not show a strong relationship with crime categories, indicating that crimes of all types occur across different districts.\n",
        "\n",
        "#### Victim_Age vs Crime_Category\n",
        "- **Observation**: Victim age does not show a strong relationship with crime categories, though some categories like \"Crimes against Persons\" have younger victims.\n",
        "- **Insight**: Most crime categories have a wide range of victim ages, with no particular age group being exclusively targeted for specific crime types.\n",
        "\n",
        "#### Premise_Code vs Crime_Category\n",
        "- **Observation**: Different crime categories are distributed across various premises, with no clear pattern.\n",
        "- **Insight**: The type of premise does not strongly differentiate between crime categories, indicating that crimes of all types occur in various locations.\n",
        "\n",
        "#### Weapon_Used_Code vs Crime_Category\n",
        "- **Observation**: Different types of crimes involve a variety of weapons, with no clear pattern linking specific weapons to crime categories.\n",
        "- **Insight**: The type of weapon used does not strongly differentiate between crime categories, suggesting that crimes of all types involve various weapons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efbd6990",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.712767Z",
          "iopub.status.busy": "2024-08-08T08:15:25.712307Z",
          "iopub.status.idle": "2024-08-08T08:15:25.719630Z",
          "shell.execute_reply": "2024-08-08T08:15:25.718389Z"
        },
        "papermill": {
          "duration": 0.031452,
          "end_time": "2024-08-08T08:15:25.722204",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.690752",
          "status": "completed"
        },
        "tags": [],
        "id": "efbd6990",
        "outputId": "5170ffa7-51b1-4f48-ad1c-e662f976ce3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n#Count Plots of Categorical Columns against Crime_Category\\nperform_eda6(train_df, 'Crime_Category')\\n\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#Count Plots of Categorical Columns against Crime_Category\n",
        "perform_eda6(train_df, 'Crime_Category')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc7157b1",
      "metadata": {
        "papermill": {
          "duration": 0.020131,
          "end_time": "2024-08-08T08:15:25.761968",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.741837",
          "status": "completed"
        },
        "tags": [],
        "id": "dc7157b1"
      },
      "source": [
        "### Count Plots of Categorical Columns Against Crime_Category\n",
        "\n",
        "#### Location vs Crime_Category\n",
        "- **Observation**: The distribution of crimes across different locations is very dense and appears uniform.\n",
        "- **Insight**: This suggests that crimes of all types are spread across many locations, making it difficult to identify specific locations associated with particular crime categories.\n",
        "\n",
        "#### Cross_Street vs Crime_Category\n",
        "- **Observation**: Similar to the Location feature, crimes are spread across many cross streets with no clear pattern.\n",
        "- **Insight**: Crimes are not concentrated on specific cross streets, indicating that the cross street information might not be a strong differentiator for crime categories.\n",
        "\n",
        "#### Area_Name vs Crime_Category\n",
        "- **Observation**: Different area names show some variation in the count of crimes, with some areas having higher crime counts.\n",
        "- **Insight**: Certain areas, such as \"N Hollywood\" and \"Newton\", have higher counts of certain crime categories, which could indicate areas with higher crime rates.\n",
        "\n",
        "#### Part1-2 vs Crime_Category\n",
        "- **Observation**: Part 1 crimes are more frequent than Part 2 crimes across all crime categories.\n",
        "- **Insight**: This indicates that Part 1 crimes, which are generally more severe, are more prevalent in the dataset.\n",
        "\n",
        "#### Modus_Operandi vs Crime_Category\n",
        "- **Observation**: The modus operandi feature shows a very dense distribution with no clear pattern.\n",
        "- **Insight**: Modus operandi does not provide a clear differentiation between crime categories, suggesting that it might not be a strong predictor.\n",
        "\n",
        "#### Victim_Sex vs Crime_Category\n",
        "- **Observation**: Males (M) are more frequently victims across most crime categories, followed by females (F).\n",
        "- **Insight**: This suggests that males are more often victims of crime, which could inform targeted prevention efforts.\n",
        "\n",
        "#### Victim_Descent vs Crime_Category\n",
        "- **Observation**: Certain descents, such as White (W) and Hispanic (H), show higher counts across various crime categories.\n",
        "- **Insight**: This indicates that crimes are more frequently reported among certain descent groups, which could reflect demographic patterns or reporting biases.\n",
        "\n",
        "#### Premise_Description vs Crime_Category\n",
        "- **Observation**: Crimes occur across a wide variety of premises, with some premises showing higher counts for certain crime categories.\n",
        "- **Insight**: Certain premises, like \"STREET\" and \"SINGLE FAMILY DWELLING\", have higher crime counts, suggesting that these locations are more prone to certain types of crimes.\n",
        "\n",
        "#### Weapon_Description vs Crime_Category\n",
        "- **Observation**: Certain weapons, like \"STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)\", are more commonly associated with specific crime categories.\n",
        "- **Insight**: This highlights the prevalence of certain weapons in specific crimes, which could inform law enforcement and public safety strategies.\n",
        "\n",
        "#### Status vs Crime_Category\n",
        "- **Observation**: The majority of cases are \"Invest Cont\", indicating that most crimes are under investigation.\n",
        "- **Insight**: The status of cases provides information on the progress and resolution of crime investigations.\n",
        "\n",
        "#### Status_Description vs Crime_Category\n",
        "- **Observation**: Similar to Status, most crimes are marked as \"Invest Cont\" across all categories.\n",
        "- **Insight**: This suggests that most cases remain under investigation, indicating a need for resources to resolve these cases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc3626f",
      "metadata": {
        "papermill": {
          "duration": 0.019135,
          "end_time": "2024-08-08T08:15:25.800862",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.781727",
          "status": "completed"
        },
        "tags": [],
        "id": "5bc3626f"
      },
      "source": [
        "<h2 style=\"color:purple;\">Data Splitting</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87685ee5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.841629Z",
          "iopub.status.busy": "2024-08-08T08:15:25.841227Z",
          "iopub.status.idle": "2024-08-08T08:15:25.848293Z",
          "shell.execute_reply": "2024-08-08T08:15:25.847222Z"
        },
        "papermill": {
          "duration": 0.030216,
          "end_time": "2024-08-08T08:15:25.850522",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.820306",
          "status": "completed"
        },
        "tags": [],
        "id": "87685ee5",
        "outputId": "3d9f42fa-08aa-4668-fdc9-d97ff1ade926"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Separate the features (X) from the target variable (y)\\nX = train_df.drop(columns=['Crime_Category'])\\ny = train_df['Crime_Category']\\n# Split the data into training and validation sets\\n# 80% of the data is used for training, 20% is used for validation\\n# random_state is set to 42 to ensure reproducibility\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\\n\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "# Separate the features (X) from the target variable (y)\n",
        "X = train_df.drop(columns=['Crime_Category'])\n",
        "y = train_df['Crime_Category']\n",
        "# Split the data into training and validation sets\n",
        "# 80% of the data is used for training, 20% is used for validation\n",
        "# random_state is set to 42 to ensure reproducibility\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "'''\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d9e881",
      "metadata": {
        "papermill": {
          "duration": 0.019361,
          "end_time": "2024-08-08T08:15:25.889840",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.870479",
          "status": "completed"
        },
        "tags": [],
        "id": "11d9e881"
      },
      "source": [
        "<h2 style=\"color:purple;\">Data Preprocessing</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19fc61b4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.932403Z",
          "iopub.status.busy": "2024-08-08T08:15:25.931993Z",
          "iopub.status.idle": "2024-08-08T08:15:25.938623Z",
          "shell.execute_reply": "2024-08-08T08:15:25.937619Z"
        },
        "papermill": {
          "duration": 0.030009,
          "end_time": "2024-08-08T08:15:25.940789",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.910780",
          "status": "completed"
        },
        "tags": [],
        "id": "19fc61b4",
        "outputId": "e72816a0-4925-435e-8b9b-1f571d3e381d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Impute missing values for numerical columns\\nnum_imputer = SimpleImputer(strategy='mean')\\nX_train[numerical_cols] = num_imputer.fit_transform(X_train[numerical_cols])\\nX_val[numerical_cols] = num_imputer.transform(X_val[numerical_cols])\\ntest_df[numerical_cols] = num_imputer.transform(test_df[numerical_cols])\\n\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Impute missing values for numerical columns\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "X_train[numerical_cols] = num_imputer.fit_transform(X_train[numerical_cols])\n",
        "X_val[numerical_cols] = num_imputer.transform(X_val[numerical_cols])\n",
        "test_df[numerical_cols] = num_imputer.transform(test_df[numerical_cols])\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5685ee5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:25.982223Z",
          "iopub.status.busy": "2024-08-08T08:15:25.981810Z",
          "iopub.status.idle": "2024-08-08T08:15:25.988713Z",
          "shell.execute_reply": "2024-08-08T08:15:25.987639Z"
        },
        "papermill": {
          "duration": 0.030487,
          "end_time": "2024-08-08T08:15:25.991015",
          "exception": false,
          "start_time": "2024-08-08T08:15:25.960528",
          "status": "completed"
        },
        "tags": [],
        "id": "a5685ee5",
        "outputId": "ce2d5076-62aa-4ee4-84ed-aa49f00e549b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Impute missing values for categorical columns\\ncat_imputer = SimpleImputer(strategy='most_frequent')\\nX_train[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\\nX_val[categorical_cols] = cat_imputer.transform(X_val[categorical_cols])\\ntest_df[categorical_cols] = cat_imputer.transform(test_df[categorical_cols])\\n\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Impute missing values for categorical columns\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\n",
        "X_val[categorical_cols] = cat_imputer.transform(X_val[categorical_cols])\n",
        "test_df[categorical_cols] = cat_imputer.transform(test_df[categorical_cols])\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d43679",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.034161Z",
          "iopub.status.busy": "2024-08-08T08:15:26.033050Z",
          "iopub.status.idle": "2024-08-08T08:15:26.041205Z",
          "shell.execute_reply": "2024-08-08T08:15:26.040092Z"
        },
        "papermill": {
          "duration": 0.03223,
          "end_time": "2024-08-08T08:15:26.043589",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.011359",
          "status": "completed"
        },
        "tags": [],
        "id": "99d43679",
        "outputId": "db0bfd4c-9d1a-48c2-d531-7503bed16962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndef frequency_encoding(column, df, df_val=None, df_test=None):\\n    freq_encoding = df[column].value_counts() / len(df)\\n    df[column + '_freq'] = df[column].map(freq_encoding)\\n    if df_val is not None:\\n        df_val[column + '_freq'] = df_val[column].map(freq_encoding)\\n    if df_test is not None:\\n        df_test[column + '_freq'] = df_test[column].map(freq_encoding)\\n    return df, df_val, df_test\\nhigh_cardinality_cols = ['Location', 'Cross_Street', 'Modus_Operandi', 'Premise_Description', 'Weapon_Description']\\nordinal_encoder_cols = ['Area_Name', 'Part1-2', 'Victim_Sex', 'Victim_Descent', 'Status', 'Status_Description']\\n# Apply Frequency Encoding for high cardinality columns\\nfor col in high_cardinality_cols:\\n    X_train, X_val, test_df = frequency_encoding(col, X_train, X_val, test_df)\\n\\n# Apply Ordinal Encoder for other categorical columns\\noe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\\nX_train[ordinal_encoder_cols] = oe.fit_transform(X_train[ordinal_encoder_cols])\\nX_val[ordinal_encoder_cols] = oe.transform(X_val[ordinal_encoder_cols])\\ntest_df[ordinal_encoder_cols] = oe.transform(test_df[ordinal_encoder_cols])\\n\\n# Drop the original high cardinality columns as we have their frequency encoded versions\\nX_train = X_train.drop(columns=high_cardinality_cols)\\nX_val = X_val.drop(columns=high_cardinality_cols)\\ntest_df = test_df.drop(columns=high_cardinality_cols)\\n\\n# Use SimpleImputer to fill any remaining missing values\\nimputer = SimpleImputer(strategy='most_frequent')\\nX_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\\nX_val = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)\\ntest_df = pd.DataFrame(imputer.transform(test_df), columns=test_df.columns)\\n\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "def frequency_encoding(column, df, df_val=None, df_test=None):\n",
        "    freq_encoding = df[column].value_counts() / len(df)\n",
        "    df[column + '_freq'] = df[column].map(freq_encoding)\n",
        "    if df_val is not None:\n",
        "        df_val[column + '_freq'] = df_val[column].map(freq_encoding)\n",
        "    if df_test is not None:\n",
        "        df_test[column + '_freq'] = df_test[column].map(freq_encoding)\n",
        "    return df, df_val, df_test\n",
        "high_cardinality_cols = ['Location', 'Cross_Street', 'Modus_Operandi', 'Premise_Description', 'Weapon_Description']\n",
        "ordinal_encoder_cols = ['Area_Name', 'Part1-2', 'Victim_Sex', 'Victim_Descent', 'Status', 'Status_Description']\n",
        "# Apply Frequency Encoding for high cardinality columns\n",
        "for col in high_cardinality_cols:\n",
        "    X_train, X_val, test_df = frequency_encoding(col, X_train, X_val, test_df)\n",
        "\n",
        "# Apply Ordinal Encoder for other categorical columns\n",
        "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X_train[ordinal_encoder_cols] = oe.fit_transform(X_train[ordinal_encoder_cols])\n",
        "X_val[ordinal_encoder_cols] = oe.transform(X_val[ordinal_encoder_cols])\n",
        "test_df[ordinal_encoder_cols] = oe.transform(test_df[ordinal_encoder_cols])\n",
        "\n",
        "# Drop the original high cardinality columns as we have their frequency encoded versions\n",
        "X_train = X_train.drop(columns=high_cardinality_cols)\n",
        "X_val = X_val.drop(columns=high_cardinality_cols)\n",
        "test_df = test_df.drop(columns=high_cardinality_cols)\n",
        "\n",
        "# Use SimpleImputer to fill any remaining missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_val = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)\n",
        "test_df = pd.DataFrame(imputer.transform(test_df), columns=test_df.columns)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d44ac8a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.088639Z",
          "iopub.status.busy": "2024-08-08T08:15:26.087375Z",
          "iopub.status.idle": "2024-08-08T08:15:26.094851Z",
          "shell.execute_reply": "2024-08-08T08:15:26.093721Z"
        },
        "papermill": {
          "duration": 0.031452,
          "end_time": "2024-08-08T08:15:26.097393",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.065941",
          "status": "completed"
        },
        "tags": [],
        "id": "8d44ac8a",
        "outputId": "881d50c3-8a49-4f76-8e9d-a0cf7d6702dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Scale numerical data\\nscaler = StandardScaler()\\nX_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\\nX_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\\ntest_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\\n\\n#Encode the target column\\nlabel_encoder = LabelEncoder() \\ny_train_encoded = label_encoder.fit_transform(y_train) \\ny_val_encoded = label_encoder.transform(y_val)\\n'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Scale numerical data\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
        "test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
        "\n",
        "#Encode the target column\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b97cfe3e",
      "metadata": {
        "papermill": {
          "duration": 0.020948,
          "end_time": "2024-08-08T08:15:26.139070",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.118122",
          "status": "completed"
        },
        "tags": [],
        "id": "b97cfe3e"
      },
      "source": [
        "<h2 style=\"color:purple;\">Correlation of Features With Target Variable</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e41abe9a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.183538Z",
          "iopub.status.busy": "2024-08-08T08:15:26.183090Z",
          "iopub.status.idle": "2024-08-08T08:15:26.190424Z",
          "shell.execute_reply": "2024-08-08T08:15:26.189216Z"
        },
        "papermill": {
          "duration": 0.031685,
          "end_time": "2024-08-08T08:15:26.192687",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.161002",
          "status": "completed"
        },
        "tags": [],
        "id": "e41abe9a",
        "outputId": "cb9596a5-59de-4660-af1d-8ef3ce3819b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Create a copy of X_train and add the encoded target column\\nX_train_copy = X_train.copy()\\nX_train_copy[\\'Crime_Category_Code\\'] = y_train_encoded\\n# Calculate the correlation matrix including the encoded target column\\ncorrelation_matrix = X_train_copy.corr()\\n# Extract correlations with the encoded target column\\ncorrelation_with_target = correlation_matrix[\\'Crime_Category_Code\\'].sort_values(ascending=False)\\nprint(\"Correlation of all columns with the target column:\")\\nprint(correlation_with_target)\\n'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Create a copy of X_train and add the encoded target column\n",
        "X_train_copy = X_train.copy()\n",
        "X_train_copy['Crime_Category_Code'] = y_train_encoded\n",
        "# Calculate the correlation matrix including the encoded target column\n",
        "correlation_matrix = X_train_copy.corr()\n",
        "# Extract correlations with the encoded target column\n",
        "correlation_with_target = correlation_matrix['Crime_Category_Code'].sort_values(ascending=False)\n",
        "print(\"Correlation of all columns with the target column:\")\n",
        "print(correlation_with_target)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e005c6",
      "metadata": {
        "papermill": {
          "duration": 0.019875,
          "end_time": "2024-08-08T08:15:26.232825",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.212950",
          "status": "completed"
        },
        "tags": [],
        "id": "09e005c6"
      },
      "source": [
        "<h3 style=\"color:purple;\">Insights from the Correlation Analysis</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf70c85",
      "metadata": {
        "papermill": {
          "duration": 0.019961,
          "end_time": "2024-08-08T08:15:26.273336",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.253375",
          "status": "completed"
        },
        "tags": [],
        "id": "edf70c85"
      },
      "source": [
        "* Highly Correlated Features:\n",
        "\n",
        " None of the features have a very high correlation with the target column Crime_Category_Code. The highest positive correlation is with Cross_Street (0.075), which is relatively low.\n",
        "\n",
        "* Moderately Correlated Features:\n",
        "\n",
        " Cross_Street (0.075), Location (0.063), and Time_Occurred (0.041) show the highest positive correlations with Crime_Category_Code. Premise_Code (-0.180) and Part 1-2 (-0.264) show moderate negative correlations with the target variable.\n",
        "\n",
        "* Weakly Correlated Features:\n",
        "\n",
        " Most features show very weak correlations (close to 0) with the target column. This suggests that these features may not be strong predictors of the crime category.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f4d196",
      "metadata": {
        "papermill": {
          "duration": 0.019948,
          "end_time": "2024-08-08T08:15:26.313893",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.293945",
          "status": "completed"
        },
        "tags": [],
        "id": "40f4d196"
      },
      "source": [
        "<h2 style=\"color:purple;\">Baseline Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5406bfc1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.355774Z",
          "iopub.status.busy": "2024-08-08T08:15:26.355376Z",
          "iopub.status.idle": "2024-08-08T08:15:26.362524Z",
          "shell.execute_reply": "2024-08-08T08:15:26.361245Z"
        },
        "papermill": {
          "duration": 0.03091,
          "end_time": "2024-08-08T08:15:26.364797",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.333887",
          "status": "completed"
        },
        "tags": [],
        "id": "5406bfc1",
        "outputId": "ecc6ad98-7f4b-4688-eae2-7ca87ed5df76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize the DummyClassifier with the strategy to always predict the most frequent class\\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\\n\\n# Fit the DummyClassifier on the training data\\ndummy_clf.fit(X_train, y_train)\\n# Make predictions on the validation set using the fitted DummyClassifier\\ny_pred = dummy_clf.predict(X_val)\\n# Calculate the accuracy of the DummyClassifier on the validation set\\naccuracy = accuracy_score(y_val, y_pred)\\n\\n# Print the accuracy of the DummyClassifier\\nprint(f\"DummyClassifier Accuracy: {accuracy}\")\\n# The accuracy_score on Validation set is 0.57575\\n'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize the DummyClassifier with the strategy to always predict the most frequent class\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "# Fit the DummyClassifier on the training data\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "# Make predictions on the validation set using the fitted DummyClassifier\n",
        "y_pred = dummy_clf.predict(X_val)\n",
        "# Calculate the accuracy of the DummyClassifier on the validation set\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "# Print the accuracy of the DummyClassifier\n",
        "print(f\"DummyClassifier Accuracy: {accuracy}\")\n",
        "# The accuracy_score on Validation set is 0.57575\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbba8f2d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.406963Z",
          "iopub.status.busy": "2024-08-08T08:15:26.406546Z",
          "iopub.status.idle": "2024-08-08T08:15:26.413952Z",
          "shell.execute_reply": "2024-08-08T08:15:26.412611Z"
        },
        "papermill": {
          "duration": 0.031509,
          "end_time": "2024-08-08T08:15:26.416563",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.385054",
          "status": "completed"
        },
        "tags": [],
        "id": "dbba8f2d",
        "outputId": "dc21f502-b4d8-4444-83bb-02b74fb70327"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Make predictions on the test set using the fitted DummyClassifier\\ntest_predictions = dummy_clf.predict(test_df)\\n# load the sample submission file to check the format of submission\\nsample = pd.read_csv(\"/kaggle/input/crime-cast-forecasting-crime-categories/sample.csv\")\\nsample.head()\\n# create the submission dataframe of desired format\\nsubmission = pd.DataFrame(columns=[\\'ID\\',\\'Crime_Category\\'])\\n# fill in the predictions made in the submission file \\nsubmission[\\'ID\\'] = [i+1 for i in range(len(test_predictions))]\\nsubmission[\\'Crime_Category\\'] = test_predictions\\n# create a csv file for submission\\n# first submission,base model,dummy classifier \\nsubmission.to_csv(\\'submission.csv\\',index=False)\\n'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Make predictions on the test set using the fitted DummyClassifier\n",
        "test_predictions = dummy_clf.predict(test_df)\n",
        "# load the sample submission file to check the format of submission\n",
        "sample = pd.read_csv(\"/kaggle/input/crime-cast-forecasting-crime-categories/sample.csv\")\n",
        "sample.head()\n",
        "# create the submission dataframe of desired format\n",
        "submission = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "# fill in the predictions made in the submission file\n",
        "submission['ID'] = [i+1 for i in range(len(test_predictions))]\n",
        "submission['Crime_Category'] = test_predictions\n",
        "# create a csv file for submission\n",
        "# first submission,base model,dummy classifier\n",
        "submission.to_csv('submission.csv',index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57073914",
      "metadata": {
        "papermill": {
          "duration": 0.020673,
          "end_time": "2024-08-08T08:15:26.457709",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.437036",
          "status": "completed"
        },
        "tags": [],
        "id": "57073914"
      },
      "source": [
        "<h2 style=\"color:purple;\">Logistic Regression Classifier</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bac4cb0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.501452Z",
          "iopub.status.busy": "2024-08-08T08:15:26.500982Z",
          "iopub.status.idle": "2024-08-08T08:15:26.508353Z",
          "shell.execute_reply": "2024-08-08T08:15:26.507200Z"
        },
        "papermill": {
          "duration": 0.031552,
          "end_time": "2024-08-08T08:15:26.510665",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.479113",
          "status": "completed"
        },
        "tags": [],
        "id": "4bac4cb0",
        "outputId": "c201ab19-5dd6-4a48-c568-b4f38599a425"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#Initialise the LogisticRegression model.\\nmodel = LogisticRegression(max_iter=10000, solver=\\'liblinear\\')\\n# Set up hyperparameter tuning with GridSearchCV\\nparam_grid = {\\n    \\'C\\': [0.1, 1, 10, 100],  # Regularization strength\\n    \\'penalty\\': [\\'l1\\', \\'l2\\'],  # Norm used in penalization\\n}\\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring=\\'accuracy\\')\\n# Fit the model with cross-validation\\ngrid_search.fit(X_train, y_train)\\nbest_params = grid_search.best_params_\\nprint(\"Best hyperparameters:\", best_params)\\n#Best parameters for LogisticRegression are: {\\'C\\': 100, \\'penalty\\': \\'l2\\'}\\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#Initialise the LogisticRegression model.\n",
        "model = LogisticRegression(max_iter=10000, solver='liblinear')\n",
        "# Set up hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # Norm used in penalization\n",
        "}\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "# Fit the model with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "#Best parameters for LogisticRegression are: {'C': 100, 'penalty': 'l2'}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef91a530",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.553868Z",
          "iopub.status.busy": "2024-08-08T08:15:26.553484Z",
          "iopub.status.idle": "2024-08-08T08:15:26.560771Z",
          "shell.execute_reply": "2024-08-08T08:15:26.559710Z"
        },
        "papermill": {
          "duration": 0.031818,
          "end_time": "2024-08-08T08:15:26.563211",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.531393",
          "status": "completed"
        },
        "tags": [],
        "id": "ef91a530",
        "outputId": "fd592f83-b624-4214-e459-aacb6153a731"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbest_model_logr = LogisticRegression(max_iter=10000, solver=\\'liblinear\\',C=100,penalty=\\'l2\\')\\n# Fit the best model on the training data\\nbest_model_logr.fit(X_train, y_train)\\n# Make predictions on the validation set\\ny_pred_logr_val = best_model_logr.predict(X_val)\\n# Calculate accuracy\\naccuracy = accuracy_score(y_val, y_pred_logr_val)\\nprint(f\"Accuracy: {accuracy}\")\\n# The accuracy_score on validation set is 0.65325\\n\\n#other metrics to understand performance\\n# Precision\\nprecision_logr = precision_score(y_val, y_pred_logr_val, average=\\'weighted\\')\\nprint(f\"Precision: {precision_logr:.4f}\")\\n# Recall\\nrecall_logr = recall_score(y_val, y_pred_logr_val, average=\\'weighted\\')\\nprint(f\"Recall: {recall_logr:.4f}\")\\n# F1 Score\\nf1_logr = f1_score(y_val, y_pred_logr_val, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_logr:.4f}\")\\n#Precision: 0.6034 Recall: 0.6532 F1 Score: 0.5891\\n'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "best_model_logr = LogisticRegression(max_iter=10000, solver='liblinear',C=100,penalty='l2')\n",
        "# Fit the best model on the training data\n",
        "best_model_logr.fit(X_train, y_train)\n",
        "# Make predictions on the validation set\n",
        "y_pred_logr_val = best_model_logr.predict(X_val)\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred_logr_val)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "# The accuracy_score on validation set is 0.65325\n",
        "\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_logr = precision_score(y_val, y_pred_logr_val, average='weighted')\n",
        "print(f\"Precision: {precision_logr:.4f}\")\n",
        "# Recall\n",
        "recall_logr = recall_score(y_val, y_pred_logr_val, average='weighted')\n",
        "print(f\"Recall: {recall_logr:.4f}\")\n",
        "# F1 Score\n",
        "f1_logr = f1_score(y_val, y_pred_logr_val, average='weighted')\n",
        "print(f\"F1 Score: {f1_logr:.4f}\")\n",
        "#Precision: 0.6034 Recall: 0.6532 F1 Score: 0.5891\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2cc564d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.607663Z",
          "iopub.status.busy": "2024-08-08T08:15:26.607234Z",
          "iopub.status.idle": "2024-08-08T08:15:26.614069Z",
          "shell.execute_reply": "2024-08-08T08:15:26.613112Z"
        },
        "papermill": {
          "duration": 0.031696,
          "end_time": "2024-08-08T08:15:26.616229",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.584533",
          "status": "completed"
        },
        "tags": [],
        "id": "b2cc564d",
        "outputId": "35496e44-984f-40a0-e12e-77bfee904ecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Make predictions on the test set using the fitted Logistic regression\\ntest_predictions_log = best_model_logr.predict(test_df)\\n# create the submission dataframe of desired format\\nsubmission_log = pd.DataFrame(columns=['ID','Crime_Category'])\\n# fill in the predictions made in the submission file \\nsubmission_log['ID'] = [i+1 for i in range(len(test_predictions_log))]\\nsubmission_log['Crime_Category'] = test_predictions_log\\n# create a csv file for submission\\n# second submission,logistic regression classifier \\nsubmission_log.to_csv('submission_log.csv',index=False)\\n\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Make predictions on the test set using the fitted Logistic regression\n",
        "test_predictions_log = best_model_logr.predict(test_df)\n",
        "# create the submission dataframe of desired format\n",
        "submission_log = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "# fill in the predictions made in the submission file\n",
        "submission_log['ID'] = [i+1 for i in range(len(test_predictions_log))]\n",
        "submission_log['Crime_Category'] = test_predictions_log\n",
        "# create a csv file for submission\n",
        "# second submission,logistic regression classifier\n",
        "submission_log.to_csv('submission_log.csv',index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c385245",
      "metadata": {
        "papermill": {
          "duration": 0.020567,
          "end_time": "2024-08-08T08:15:26.657737",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.637170",
          "status": "completed"
        },
        "tags": [],
        "id": "6c385245"
      },
      "source": [
        "<h2 style=\"color:purple;\">Logistic Regression With Polynomial Features</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c45591",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.701253Z",
          "iopub.status.busy": "2024-08-08T08:15:26.700774Z",
          "iopub.status.idle": "2024-08-08T08:15:26.708374Z",
          "shell.execute_reply": "2024-08-08T08:15:26.707114Z"
        },
        "papermill": {
          "duration": 0.032265,
          "end_time": "2024-08-08T08:15:26.710810",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.678545",
          "status": "completed"
        },
        "tags": [],
        "id": "f2c45591",
        "outputId": "8112d200-aa3f-41ae-992d-72cfe95e2482"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize polynomial features\\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\\n# Fit and transform the polynomial features for the training data\\nX_train_poly = poly.fit_transform(X_train)\\n\\n# Transform the polynomial features for the validation and test data\\nX_val_poly = poly.transform(X_val)\\ntest_df_poly = poly.transform(test_df)\\n'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize polynomial features\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "# Fit and transform the polynomial features for the training data\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "\n",
        "# Transform the polynomial features for the validation and test data\n",
        "X_val_poly = poly.transform(X_val)\n",
        "test_df_poly = poly.transform(test_df)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f2699a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.756047Z",
          "iopub.status.busy": "2024-08-08T08:15:26.755043Z",
          "iopub.status.idle": "2024-08-08T08:15:26.763058Z",
          "shell.execute_reply": "2024-08-08T08:15:26.761601Z"
        },
        "papermill": {
          "duration": 0.033991,
          "end_time": "2024-08-08T08:15:26.765840",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.731849",
          "status": "completed"
        },
        "tags": [],
        "id": "61f2699a",
        "outputId": "e7395889-9984-4535-9df1-e3a8c48cd6fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nmodel = LogisticRegression(max_iter=10000, solver=\\'liblinear\\')\\n# Set up hyperparameter tuning with GridSearchCV\\nparam_grid = {\\n    \\'C\\': [0.1, 1, 10, 100],  # Regularization strength\\n    \\'penalty\\': [\\'l1\\', \\'l2\\'],  # Norm used in penalization\\n}\\ngrid_search_poly = GridSearchCV(model, param_grid, cv=5, scoring=\\'accuracy\\', verbose=3, n_jobs=-1)\\n# Fit the model with cross-validation on polynomial features\\ngrid_search_poly.fit(X_train_poly, y_train)\\n# Best parameters found by GridSearchCV\\nbest_params_poly = grid_search_poly.best_params_\\nprint(\"Best hyperparameters:\", best_params_poly)\\n#Best Hyperparameters are: {\\'C\\': 1, \\'penalty\\': \\'l1\\'}\\n'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "model = LogisticRegression(max_iter=10000, solver='liblinear')\n",
        "# Set up hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # Norm used in penalization\n",
        "}\n",
        "grid_search_poly = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=3, n_jobs=-1)\n",
        "# Fit the model with cross-validation on polynomial features\n",
        "grid_search_poly.fit(X_train_poly, y_train)\n",
        "# Best parameters found by GridSearchCV\n",
        "best_params_poly = grid_search_poly.best_params_\n",
        "print(\"Best hyperparameters:\", best_params_poly)\n",
        "#Best Hyperparameters are: {'C': 1, 'penalty': 'l1'}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a770cd9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.810696Z",
          "iopub.status.busy": "2024-08-08T08:15:26.810293Z",
          "iopub.status.idle": "2024-08-08T08:15:26.817826Z",
          "shell.execute_reply": "2024-08-08T08:15:26.816766Z"
        },
        "papermill": {
          "duration": 0.032832,
          "end_time": "2024-08-08T08:15:26.820227",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.787395",
          "status": "completed"
        },
        "tags": [],
        "id": "1a770cd9",
        "outputId": "12cf4268-3502-4655-b517-501470390b8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbest_model = LogisticRegression(C=1, max_iter=10000, penalty=\\'l1\\', solver=\\'liblinear\\')\\n# Fit the best model on the training data with polynomial features\\nbest_model.fit(X_train_poly, y_train)\\n# Make predictions on the validation set with polynomial features\\ny_pred_val = best_model.predict(X_val_poly)\\naccuracy_val = accuracy_score(y_val, y_pred_val)\\nprint(f\"Validation Accuracy: {accuracy_val}\")\\n#The acuuracy_score on validation set is 0.74775\\n#other metrics to understand performance\\n# Precision\\nprecision_logr_poly = precision_score(y_val, y_pred_val, average=\\'weighted\\')\\nprint(f\"Precision: {precision_logr_poly:.4f}\")\\n\\n# Recall\\nrecall_logr_poly = recall_score(y_val, y_pred_val, average=\\'weighted\\')\\nprint(f\"Recall: {recall_logr_poly:.4f}\")\\n\\n# F1 Score\\nf1_logr_poly = f1_score(y_val, y_pred_val, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_logr_poly:.4f}\")\\n#Precision: 0.7393 Recall: 0.7482 F1 Score: 0.7265\\n'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "best_model = LogisticRegression(C=1, max_iter=10000, penalty='l1', solver='liblinear')\n",
        "# Fit the best model on the training data with polynomial features\n",
        "best_model.fit(X_train_poly, y_train)\n",
        "# Make predictions on the validation set with polynomial features\n",
        "y_pred_val = best_model.predict(X_val_poly)\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "print(f\"Validation Accuracy: {accuracy_val}\")\n",
        "#The acuuracy_score on validation set is 0.74775\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_logr_poly = precision_score(y_val, y_pred_val, average='weighted')\n",
        "print(f\"Precision: {precision_logr_poly:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_logr_poly = recall_score(y_val, y_pred_val, average='weighted')\n",
        "print(f\"Recall: {recall_logr_poly:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_logr_poly = f1_score(y_val, y_pred_val, average='weighted')\n",
        "print(f\"F1 Score: {f1_logr_poly:.4f}\")\n",
        "#Precision: 0.7393 Recall: 0.7482 F1 Score: 0.7265\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef5a7fe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.865788Z",
          "iopub.status.busy": "2024-08-08T08:15:26.865358Z",
          "iopub.status.idle": "2024-08-08T08:15:26.872902Z",
          "shell.execute_reply": "2024-08-08T08:15:26.871678Z"
        },
        "papermill": {
          "duration": 0.032958,
          "end_time": "2024-08-08T08:15:26.875200",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.842242",
          "status": "completed"
        },
        "tags": [],
        "id": "8ef5a7fe",
        "outputId": "9d9bbe61-b826-4c2e-eeb0-decbca67ae34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ntest_predictions_log_p = best_model.predict(test_df_poly)\\n# create the submission dataframe of desired format\\nsubmission_log_p = pd.DataFrame(columns=['ID','Crime_Category'])\\n# fill in the predictions made in the submission file \\nsubmission_log_p['ID'] = [i+1 for i in range(len(test_predictions_log_p))]\\nsubmission_log_p['Crime_Category'] = test_predictions_log_p\\n# create a csv file for submission\\n#Logistic regression classiefier with polynomial degrees\\nsubmission_log_p.to_csv('submission_log_p.csv',index=False)\\n\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "test_predictions_log_p = best_model.predict(test_df_poly)\n",
        "# create the submission dataframe of desired format\n",
        "submission_log_p = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "# fill in the predictions made in the submission file\n",
        "submission_log_p['ID'] = [i+1 for i in range(len(test_predictions_log_p))]\n",
        "submission_log_p['Crime_Category'] = test_predictions_log_p\n",
        "# create a csv file for submission\n",
        "#Logistic regression classiefier with polynomial degrees\n",
        "submission_log_p.to_csv('submission_log_p.csv',index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f388e1",
      "metadata": {
        "papermill": {
          "duration": 0.021491,
          "end_time": "2024-08-08T08:15:26.918285",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.896794",
          "status": "completed"
        },
        "tags": [],
        "id": "35f388e1"
      },
      "source": [
        "<h2 style=\"color:purple;\">Random Forest Classifier</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96978d9f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:26.963873Z",
          "iopub.status.busy": "2024-08-08T08:15:26.963433Z",
          "iopub.status.idle": "2024-08-08T08:15:26.971077Z",
          "shell.execute_reply": "2024-08-08T08:15:26.969844Z"
        },
        "papermill": {
          "duration": 0.033332,
          "end_time": "2024-08-08T08:15:26.973403",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.940071",
          "status": "completed"
        },
        "tags": [],
        "id": "96978d9f",
        "outputId": "4597262f-d173-4724-9d3b-cfef3134c241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize the Random Forest model\\nrf_model = RandomForestClassifier(random_state=42)\\n# Set up hyperparameter tuning with GridSearchCV\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300],  # Number of trees in the forest\\n    \\'max_depth\\': [None, 10, 20, 30],  # Maximum depth of the tree\\n    \\'min_samples_split\\': [2, 5, 10],  # Minimum number of samples required to split an internal node\\n    \\'min_samples_leaf\\': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\\n} \\ngrid_search_rf = GridSearchCV(rf_model, param_grid, cv=5, scoring=\\'accuracy\\', verbose=3, n_jobs=-1)\\n# Fit the model with cross-validation\\ngrid_search_rf.fit(X_train, y_train)\\n# Best parameters found by GridSearchCV\\nbest_params_rf = grid_search_rf.best_params_\\nprint(\"Best hyperparameters:\", best_params_rf)\\n#Best Hyperparameters are : {\\'max_depth\\': None, \\'min_samples_leaf\\': 1, \\'min_samples_split\\': 5, \\'n_estimators\\': 200}\\n'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "# Set up hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "grid_search_rf = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy', verbose=3, n_jobs=-1)\n",
        "# Fit the model with cross-validation\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "# Best parameters found by GridSearchCV\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "print(\"Best hyperparameters:\", best_params_rf)\n",
        "#Best Hyperparameters are : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "382b64af",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.018388Z",
          "iopub.status.busy": "2024-08-08T08:15:27.017945Z",
          "iopub.status.idle": "2024-08-08T08:15:27.025724Z",
          "shell.execute_reply": "2024-08-08T08:15:27.024466Z"
        },
        "papermill": {
          "duration": 0.03326,
          "end_time": "2024-08-08T08:15:27.028221",
          "exception": false,
          "start_time": "2024-08-08T08:15:26.994961",
          "status": "completed"
        },
        "tags": [],
        "id": "382b64af",
        "outputId": "10bf8496-1ca5-4159-c807-630f7e4246ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbest_rf_model = RandomForestClassifier(\\n    random_state=42,\\n    max_depth=None,\\n    min_samples_leaf=1,\\n    min_samples_split=5,\\n    n_estimators=200\\n)\\n# Fit the best model on the training data\\nbest_rf_model.fit(X_train, y_train)\\n# Make predictions on the validation set\\ny_pred_val_rf = best_rf_model.predict(X_val)\\n# Calculate accuracy on the validation set\\naccuracy_val_rf = accuracy_score(y_val, y_pred_val_rf)\\nprint(f\"Validation Accuracy: {accuracy_val_rf}\")\\n#Accuracy Score on validation set is : 0.875\\n#other metrics to understand performance\\n# Precision\\nprecision_rf = precision_score(y_val, y_pred_val_rf, average=\\'weighted\\')\\nprint(f\"Precision: {precision_rf:.4f}\")\\n\\n# Recall\\nrecall_rf = recall_score(y_val, y_pred_val_rf, average=\\'weighted\\')\\nprint(f\"Recall: {recall_rf:.4f}\")\\n\\n# F1 Score\\nf1_rf = f1_score(y_val, y_pred_val_rf, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_rf:.4f}\")\\n#Precision: 0.8687 Recall: 0.8750 F1 Score: 0.8676\\n'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "best_rf_model = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=5,\n",
        "    n_estimators=200\n",
        ")\n",
        "# Fit the best model on the training data\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "# Make predictions on the validation set\n",
        "y_pred_val_rf = best_rf_model.predict(X_val)\n",
        "# Calculate accuracy on the validation set\n",
        "accuracy_val_rf = accuracy_score(y_val, y_pred_val_rf)\n",
        "print(f\"Validation Accuracy: {accuracy_val_rf}\")\n",
        "#Accuracy Score on validation set is : 0.875\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_rf = precision_score(y_val, y_pred_val_rf, average='weighted')\n",
        "print(f\"Precision: {precision_rf:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_rf = recall_score(y_val, y_pred_val_rf, average='weighted')\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_rf = f1_score(y_val, y_pred_val_rf, average='weighted')\n",
        "print(f\"F1 Score: {f1_rf:.4f}\")\n",
        "#Precision: 0.8687 Recall: 0.8750 F1 Score: 0.8676\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9295f212",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.075650Z",
          "iopub.status.busy": "2024-08-08T08:15:27.075242Z",
          "iopub.status.idle": "2024-08-08T08:15:27.082397Z",
          "shell.execute_reply": "2024-08-08T08:15:27.081237Z"
        },
        "papermill": {
          "duration": 0.034711,
          "end_time": "2024-08-08T08:15:27.084774",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.050063",
          "status": "completed"
        },
        "tags": [],
        "id": "9295f212",
        "outputId": "64f8a0d5-74d3-4f5d-89e3-e1e738affc76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Make predictions on the test set\\ny_pred_test_rf = best_rf_model.predict(test_df)\\n#create the submission dataframe of desired format\\nsubmission_rf_new = pd.DataFrame(columns=['ID','Crime_Category'])\\n# fill in the predictions made in the submission file \\nsubmission_rf_new['ID'] = [i+1 for i in range(len(y_pred_test_rf))]\\nsubmission_rf_new['Crime_Category'] = y_pred_test_rf\\n# create a csv file for submission\\n#Random Forest Classifier\\nsubmission_rf_new.to_csv('submission_rf_new.csv',index=False)\\n\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Make predictions on the test set\n",
        "y_pred_test_rf = best_rf_model.predict(test_df)\n",
        "#create the submission dataframe of desired format\n",
        "submission_rf_new = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "# fill in the predictions made in the submission file\n",
        "submission_rf_new['ID'] = [i+1 for i in range(len(y_pred_test_rf))]\n",
        "submission_rf_new['Crime_Category'] = y_pred_test_rf\n",
        "# create a csv file for submission\n",
        "#Random Forest Classifier\n",
        "submission_rf_new.to_csv('submission_rf_new.csv',index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcbc918",
      "metadata": {
        "papermill": {
          "duration": 0.022347,
          "end_time": "2024-08-08T08:15:27.128807",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.106460",
          "status": "completed"
        },
        "tags": [],
        "id": "efcbc918"
      },
      "source": [
        "<h2 style=\"color:purple;\">XGBoost Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ccacd2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.175134Z",
          "iopub.status.busy": "2024-08-08T08:15:27.174764Z",
          "iopub.status.idle": "2024-08-08T08:15:27.181922Z",
          "shell.execute_reply": "2024-08-08T08:15:27.180873Z"
        },
        "papermill": {
          "duration": 0.03346,
          "end_time": "2024-08-08T08:15:27.184020",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.150560",
          "status": "completed"
        },
        "tags": [],
        "id": "78ccacd2",
        "outputId": "050a98f2-f6cb-402c-db58-633178f3a647"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize the XGBoost classifier\\nxgb_model = xgb.XGBClassifier(random_state=42)\\n# Set up hyperparameter tuning with GridSearchCV\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'max_depth\\': [3, 5, 7],\\n    \\'learning_rate\\': [0.01, 0.1, 0.2],\\n    \\'subsample\\': [0.7, 0.8, 0.9],\\n    \\'colsample_bytree\\': [0.7, 0.8, 0.9]\\n}\\ngrid_search_xgb = GridSearchCV(xgb_model, param_grid, cv=5, scoring=\\'accuracy\\', verbose=3, n_jobs=-1)\\n# Fit the model with cross-validation\\ngrid_search_xgb.fit(X_train, y_train_encoded)\\n# Best parameters found by GridSearchCV\\nbest_params = grid_search_xgb.best_params_\\nprint(\"Best hyperparameters:\", best_params)\\n#Best Hyperparameters : {\\'colsample_bytree\\': 0.7, \\'learning_rate\\': 0.1, \\'max_depth\\': 7, \\'n_estimators\\': 100, \\'subsample\\': 0.9}\\n'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "# Set up hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}\n",
        "grid_search_xgb = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy', verbose=3, n_jobs=-1)\n",
        "# Fit the model with cross-validation\n",
        "grid_search_xgb.fit(X_train, y_train_encoded)\n",
        "# Best parameters found by GridSearchCV\n",
        "best_params = grid_search_xgb.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "#Best Hyperparameters : {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.9}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45a8e99",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.229530Z",
          "iopub.status.busy": "2024-08-08T08:15:27.229110Z",
          "iopub.status.idle": "2024-08-08T08:15:27.236570Z",
          "shell.execute_reply": "2024-08-08T08:15:27.235522Z"
        },
        "papermill": {
          "duration": 0.033212,
          "end_time": "2024-08-08T08:15:27.239025",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.205813",
          "status": "completed"
        },
        "tags": [],
        "id": "d45a8e99",
        "outputId": "e4d7bf61-57eb-4fec-a93c-6f9ca2064840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbest_xgb_model = xgb.XGBClassifier(\\n    random_state=42,\\n    colsample_bytree=0.7,\\n    learning_rate=0.1,\\n    max_depth=7,\\n    n_estimators=100,\\n    subsample=0.9\\n)\\n# Fit the best model on the training data\\nbest_xgb_model.fit(X_train, y_train_encoded)\\n# Make predictions on the validation set\\ny_pred_val = best_xgb_model.predict(X_val)\\n# Decode the predictions back to original labels\\ny_pred_val_decoded = label_encoder.inverse_transform(y_pred_val)\\n# Calculate accuracy on the validation set\\naccuracy_val = accuracy_score(y_val, y_pred_val_decoded)\\nprint(f\"Validation Accuracy: {accuracy_val}\")\\n#Accuracy Score on the validation set is : 0.86125\\n#other metrics to understand performance\\n# Precision\\nprecision_xgb = precision_score(y_val, y_pred_val_decoded, average=\\'weighted\\')\\nprint(f\"Precision: {precision_xgb:.4f}\")\\n\\n# Recall\\nrecall_xgb = recall_score(y_val, y_pred_val_decoded, average=\\'weighted\\')\\nprint(f\"Recall: {recall_xgb:.4f}\")\\n\\n# F1 Score\\nf1_xgb = f1_score(y_val, y_pred_val_decoded, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_xgb:.4f}\")\\n#Precision: 0.8774 Recall: 0.8612 F1 Score: 0.8600\\n'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "best_xgb_model = xgb.XGBClassifier(\n",
        "    random_state=42,\n",
        "    colsample_bytree=0.7,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    n_estimators=100,\n",
        "    subsample=0.9\n",
        ")\n",
        "# Fit the best model on the training data\n",
        "best_xgb_model.fit(X_train, y_train_encoded)\n",
        "# Make predictions on the validation set\n",
        "y_pred_val = best_xgb_model.predict(X_val)\n",
        "# Decode the predictions back to original labels\n",
        "y_pred_val_decoded = label_encoder.inverse_transform(y_pred_val)\n",
        "# Calculate accuracy on the validation set\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val_decoded)\n",
        "print(f\"Validation Accuracy: {accuracy_val}\")\n",
        "#Accuracy Score on the validation set is : 0.86125\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_xgb = precision_score(y_val, y_pred_val_decoded, average='weighted')\n",
        "print(f\"Precision: {precision_xgb:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_xgb = recall_score(y_val, y_pred_val_decoded, average='weighted')\n",
        "print(f\"Recall: {recall_xgb:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_xgb = f1_score(y_val, y_pred_val_decoded, average='weighted')\n",
        "print(f\"F1 Score: {f1_xgb:.4f}\")\n",
        "#Precision: 0.8774 Recall: 0.8612 F1 Score: 0.8600\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7ca62a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.285946Z",
          "iopub.status.busy": "2024-08-08T08:15:27.285567Z",
          "iopub.status.idle": "2024-08-08T08:15:27.293226Z",
          "shell.execute_reply": "2024-08-08T08:15:27.291889Z"
        },
        "papermill": {
          "duration": 0.035053,
          "end_time": "2024-08-08T08:15:27.295956",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.260903",
          "status": "completed"
        },
        "tags": [],
        "id": "6d7ca62a",
        "outputId": "e666704b-7ba9-4d5d-b138-c3523103f14f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Make predictions on the test set\\ny_pred_test = best_xgb_model.predict(test_df)\\n# Decode the test predictions back to original labels\\ny_pred_test_decoded = label_encoder.inverse_transform(y_pred_test)\\n# create the submission dataframe of desired format\\nsubmission_xgb_new = pd.DataFrame(columns=['ID','Crime_Category'])\\n# fill in the predictions made in the submission file \\nsubmission_xgb_new['ID'] = [i+1 for i in range(len(y_pred_test_decoded))]\\nsubmission_xgb_new['Crime_Category'] = y_pred_test_decoded\\n# create a csv file for submission\\nsubmission_xgb_new.to_csv('submission_xgb_new.csv',index=False)\\n\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "# Make predictions on the test set\n",
        "y_pred_test = best_xgb_model.predict(test_df)\n",
        "# Decode the test predictions back to original labels\n",
        "y_pred_test_decoded = label_encoder.inverse_transform(y_pred_test)\n",
        "# create the submission dataframe of desired format\n",
        "submission_xgb_new = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "# fill in the predictions made in the submission file\n",
        "submission_xgb_new['ID'] = [i+1 for i in range(len(y_pred_test_decoded))]\n",
        "submission_xgb_new['Crime_Category'] = y_pred_test_decoded\n",
        "# create a csv file for submission\n",
        "submission_xgb_new.to_csv('submission_xgb_new.csv',index=False)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af074a7",
      "metadata": {
        "papermill": {
          "duration": 0.02226,
          "end_time": "2024-08-08T08:15:27.340601",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.318341",
          "status": "completed"
        },
        "tags": [],
        "id": "4af074a7"
      },
      "source": [
        "<h2 style=\"color:purple;\">KNeighborsClassifier</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f09edd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.387578Z",
          "iopub.status.busy": "2024-08-08T08:15:27.387172Z",
          "iopub.status.idle": "2024-08-08T08:15:27.394206Z",
          "shell.execute_reply": "2024-08-08T08:15:27.393202Z"
        },
        "papermill": {
          "duration": 0.032993,
          "end_time": "2024-08-08T08:15:27.396467",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.363474",
          "status": "completed"
        },
        "tags": [],
        "id": "24f09edd",
        "outputId": "3afa1d1a-f5a3-4d40-df90-b17e18473b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize the KNN classifier\\nknn = KNeighborsClassifier()\\n# Set up hyperparameter tuning with GridSearchCV\\nparam_grid_knn = {\\n    \\'n_neighbors\\': [3, 5, 7, 9],\\n    \\'weights\\': [\\'uniform\\', \\'distance\\'],\\n    \\'metric\\': [\\'euclidean\\', \\'manhattan\\', \\'minkowski\\']\\n}\\ngrid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring=\\'accuracy\\', verbose=3, n_jobs=-1)\\n# Fit the model with cross-validation\\ngrid_search_knn.fit(X_train, y_train_encoded)\\n# Best parameters found by GridSearchCV\\nbest_params_knn = grid_search_knn.best_params_\\nprint(\"Best hyperparameters for KNN:\", best_params_knn)\\n#Best hyperparameters for KNN: {\\'metric\\': \\'manhattan\\', \\'n_neighbors\\': 9, \\'weights\\': \\'distance\\'}\\n'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize the KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "# Set up hyperparameter tuning with GridSearchCV\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', verbose=3, n_jobs=-1)\n",
        "# Fit the model with cross-validation\n",
        "grid_search_knn.fit(X_train, y_train_encoded)\n",
        "# Best parameters found by GridSearchCV\n",
        "best_params_knn = grid_search_knn.best_params_\n",
        "print(\"Best hyperparameters for KNN:\", best_params_knn)\n",
        "#Best hyperparameters for KNN: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bff0afe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.443711Z",
          "iopub.status.busy": "2024-08-08T08:15:27.443316Z",
          "iopub.status.idle": "2024-08-08T08:15:27.451226Z",
          "shell.execute_reply": "2024-08-08T08:15:27.450022Z"
        },
        "papermill": {
          "duration": 0.035184,
          "end_time": "2024-08-08T08:15:27.453614",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.418430",
          "status": "completed"
        },
        "tags": [],
        "id": "9bff0afe",
        "outputId": "17345b7e-493b-43a5-9d5e-1be1124d7428"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbest_knn_model = KNeighborsClassifier(metric=\"manhattan\",n_neighbors = 9,weights = \"distance\")\\nbest_knn_model.fit(X_train,y_train_encoded)\\n# Make predictions on the validation set\\ny_pred_val_knn = best_knn_model.predict(X_val)\\n# Decode the predictions back to original labels\\ny_pred_val_knn_decoded = label_encoder.inverse_transform(y_pred_val_knn)\\n# Calculate accuracy on the validation set\\naccuracy_val_knn = accuracy_score(y_val, y_pred_val_knn_decoded)\\nprint(f\"KNN Validation Accuracy: {accuracy_val_knn}\")\\n#Accuracy Score on Validation set is : 0.49725\\n#other metrics to understand performance\\n# Precision\\nprecision_knn = precision_score(y_val, y_pred_val_knn_decoded, average=\\'weighted\\')\\nprint(f\"Precision: {precision_knn:.4f}\")\\n\\n# Recall\\nrecall_knn = recall_score(y_val, y_pred_val_knn_decoded, average=\\'weighted\\')\\nprint(f\"Recall: {recall_knn:.4f}\")\\n\\n# F1 Score\\nf1_knn = f1_score(y_val, y_pred_val_knn_decoded, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_knn:.4f}\")\\n#Precision: 0.7602 Recall: 0.4973 F1 Score: 0.5480\\n'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "best_knn_model = KNeighborsClassifier(metric=\"manhattan\",n_neighbors = 9,weights = \"distance\")\n",
        "best_knn_model.fit(X_train,y_train_encoded)\n",
        "# Make predictions on the validation set\n",
        "y_pred_val_knn = best_knn_model.predict(X_val)\n",
        "# Decode the predictions back to original labels\n",
        "y_pred_val_knn_decoded = label_encoder.inverse_transform(y_pred_val_knn)\n",
        "# Calculate accuracy on the validation set\n",
        "accuracy_val_knn = accuracy_score(y_val, y_pred_val_knn_decoded)\n",
        "print(f\"KNN Validation Accuracy: {accuracy_val_knn}\")\n",
        "#Accuracy Score on Validation set is : 0.49725\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_knn = precision_score(y_val, y_pred_val_knn_decoded, average='weighted')\n",
        "print(f\"Precision: {precision_knn:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_knn = recall_score(y_val, y_pred_val_knn_decoded, average='weighted')\n",
        "print(f\"Recall: {recall_knn:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_knn = f1_score(y_val, y_pred_val_knn_decoded, average='weighted')\n",
        "print(f\"F1 Score: {f1_knn:.4f}\")\n",
        "#Precision: 0.7602 Recall: 0.4973 F1 Score: 0.5480\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53495a6",
      "metadata": {
        "papermill": {
          "duration": 0.022373,
          "end_time": "2024-08-08T08:15:27.499839",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.477466",
          "status": "completed"
        },
        "tags": [],
        "id": "a53495a6"
      },
      "source": [
        "<h2 style=\"color:purple;\">LightGBM</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b037bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.545830Z",
          "iopub.status.busy": "2024-08-08T08:15:27.545445Z",
          "iopub.status.idle": "2024-08-08T08:15:27.553025Z",
          "shell.execute_reply": "2024-08-08T08:15:27.551645Z"
        },
        "papermill": {
          "duration": 0.033527,
          "end_time": "2024-08-08T08:15:27.555466",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.521939",
          "status": "completed"
        },
        "tags": [],
        "id": "86b037bf",
        "outputId": "e705a801-bf29-4d75-c110-de902538ea00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Initialize the LightGBM classifier\\nlgb_model = lgb.LGBMClassifier(random_state=42)\\n# Set up hyperparameter tuning with RandomizedSearchCV\\nparam_dist = {\\n    'n_estimators': randint(100, 500),\\n    'max_depth': randint(3, 10),\\n    'learning_rate': uniform(0.01, 0.2),\\n    'subsample': uniform(0.7, 0.3),\\n    'colsample_bytree': uniform(0.7, 0.3),\\n    'num_leaves': randint(2**3, 2**10),\\n    'min_data_in_leaf': randint(10, 100),  # Ensuring there are enough data points in a leaf\\n    'min_gain_to_split': uniform(0.0, 0.2)  # Requiring a minimum gain for splits\\n}\\nrandom_search_lgb = RandomizedSearchCV(lgb_model, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', verbose=3, n_jobs=-1, random_state=42)\\nrandom_search_lgb.fit(X_train,y_train_encoded)\\nbest_params_lgb = random_search_lgb.best_params_\\n#Best hyperparameters for LightGBM: {'colsample_bytree': 0.7110049608671793, 'learning_rate': 0.06048738886880416, 'max_depth': 9, 'min_data_in_leaf': 12, 'min_gain_to_split': 0.17904136753743988, 'n_estimators': 337, 'num_leaves': 370, 'subsample': 0.8596340455795947}\\n\""
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize the LightGBM classifier\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
        "# Set up hyperparameter tuning with RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'subsample': uniform(0.7, 0.3),\n",
        "    'colsample_bytree': uniform(0.7, 0.3),\n",
        "    'num_leaves': randint(2**3, 2**10),\n",
        "    'min_data_in_leaf': randint(10, 100),  # Ensuring there are enough data points in a leaf\n",
        "    'min_gain_to_split': uniform(0.0, 0.2)  # Requiring a minimum gain for splits\n",
        "}\n",
        "random_search_lgb = RandomizedSearchCV(lgb_model, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', verbose=3, n_jobs=-1, random_state=42)\n",
        "random_search_lgb.fit(X_train,y_train_encoded)\n",
        "best_params_lgb = random_search_lgb.best_params_\n",
        "#Best hyperparameters for LightGBM: {'colsample_bytree': 0.7110049608671793, 'learning_rate': 0.06048738886880416, 'max_depth': 9, 'min_data_in_leaf': 12, 'min_gain_to_split': 0.17904136753743988, 'n_estimators': 337, 'num_leaves': 370, 'subsample': 0.8596340455795947}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b8fd32",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.603409Z",
          "iopub.status.busy": "2024-08-08T08:15:27.602512Z",
          "iopub.status.idle": "2024-08-08T08:15:27.610760Z",
          "shell.execute_reply": "2024-08-08T08:15:27.609545Z"
        },
        "papermill": {
          "duration": 0.034937,
          "end_time": "2024-08-08T08:15:27.613081",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.578144",
          "status": "completed"
        },
        "tags": [],
        "id": "d3b8fd32",
        "outputId": "76c25746-442c-4fc1-8f65-4dca87889244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize the LightGBM classifier with best parameters\\nbest_params_lgb = {\\n    \\'colsample_bytree\\': 0.7110049608671793,\\n    \\'learning_rate\\': 0.06048738886880416,\\n    \\'max_depth\\': 9,\\n    \\'min_data_in_leaf\\': 12,\\n    \\'min_gain_to_split\\': 0.17904136753743988,\\n    \\'n_estimators\\': 337,\\n    \\'num_leaves\\': 370,\\n    \\'subsample\\': 0.8596340455795947\\n}\\nbest_lgb_model = lgb.LGBMClassifier(random_state=42, **best_params_lgb,verbose=-1)\\n# Fit the best model on the training data\\nbest_lgb_model.fit(X_train, y_train_encoded)\\n# Make predictions on the validation set\\ny_pred_val_lgb = best_lgb_model.predict(X_val)\\n# Decode the predictions back to original labels\\ny_pred_val_lgb_decoded = label_encoder.inverse_transform(y_pred_val_lgb)\\n# Calculate accuracy on the validation set\\naccuracy_val_lgb = accuracy_score(y_val, y_pred_val_lgb_decoded)\\nprint(f\"LightGBM Validation Accuracy: {accuracy_val_lgb}\")\\n#Accuracy Score on the validation set is : 0.85825\\n# Precision\\nprecision_lgbm = precision_score(y_val, y_pred_val_lgb_decoded, average=\\'weighted\\')\\nprint(f\"Precision: {precision_lgbm:.4f}\")\\n\\n# Recall\\nrecall_lgbm = recall_score(y_val, y_pred_val_lgb_decoded, average=\\'weighted\\')\\nprint(f\"Recall: {recall_lgbm:.4f}\")\\n\\n# F1 Score\\nf1_lgbm = f1_score(y_val, y_pred_val_lgb_decoded, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_lgbm:.4f}\")\\n#Precision: 0.8759 Recall: 0.8582 F1 Score: 0.8566\\n'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize the LightGBM classifier with best parameters\n",
        "best_params_lgb = {\n",
        "    'colsample_bytree': 0.7110049608671793,\n",
        "    'learning_rate': 0.06048738886880416,\n",
        "    'max_depth': 9,\n",
        "    'min_data_in_leaf': 12,\n",
        "    'min_gain_to_split': 0.17904136753743988,\n",
        "    'n_estimators': 337,\n",
        "    'num_leaves': 370,\n",
        "    'subsample': 0.8596340455795947\n",
        "}\n",
        "best_lgb_model = lgb.LGBMClassifier(random_state=42, **best_params_lgb,verbose=-1)\n",
        "# Fit the best model on the training data\n",
        "best_lgb_model.fit(X_train, y_train_encoded)\n",
        "# Make predictions on the validation set\n",
        "y_pred_val_lgb = best_lgb_model.predict(X_val)\n",
        "# Decode the predictions back to original labels\n",
        "y_pred_val_lgb_decoded = label_encoder.inverse_transform(y_pred_val_lgb)\n",
        "# Calculate accuracy on the validation set\n",
        "accuracy_val_lgb = accuracy_score(y_val, y_pred_val_lgb_decoded)\n",
        "print(f\"LightGBM Validation Accuracy: {accuracy_val_lgb}\")\n",
        "#Accuracy Score on the validation set is : 0.85825\n",
        "# Precision\n",
        "precision_lgbm = precision_score(y_val, y_pred_val_lgb_decoded, average='weighted')\n",
        "print(f\"Precision: {precision_lgbm:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_lgbm = recall_score(y_val, y_pred_val_lgb_decoded, average='weighted')\n",
        "print(f\"Recall: {recall_lgbm:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_lgbm = f1_score(y_val, y_pred_val_lgb_decoded, average='weighted')\n",
        "print(f\"F1 Score: {f1_lgbm:.4f}\")\n",
        "#Precision: 0.8759 Recall: 0.8582 F1 Score: 0.8566\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188d46e9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.659952Z",
          "iopub.status.busy": "2024-08-08T08:15:27.659560Z",
          "iopub.status.idle": "2024-08-08T08:15:27.666928Z",
          "shell.execute_reply": "2024-08-08T08:15:27.665771Z"
        },
        "papermill": {
          "duration": 0.033632,
          "end_time": "2024-08-08T08:15:27.669228",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.635596",
          "status": "completed"
        },
        "tags": [],
        "id": "188d46e9",
        "outputId": "bbf6217e-1e76-41d4-9c46-4fa389435006"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ny_pred_test_lgb = best_lgb_model.predict(test_df)\\n#Decode the test predictions back to original labels\\ny_pred_test_lgb_decoded = label_encoder.inverse_transform(y_pred_test_lgb)\\n#create the submission dataframe of desired format\\nsubmission_lgb_new = pd.DataFrame(columns=['ID','Crime_Category'])\\n#fill in the predictions made in the submission file\\nsubmission_lgb_new['ID'] = [i+1 for i in range(len(y_pred_test_lgb_decoded))] \\nsubmission_lgb_new['Crime_Category'] = y_pred_test_lgb_decoded\\n#create a csv file for submission\\nsubmission_lgb_new.to_csv('submission_lgb_new.csv',index=False)\\n\""
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "y_pred_test_lgb = best_lgb_model.predict(test_df)\n",
        "#Decode the test predictions back to original labels\n",
        "y_pred_test_lgb_decoded = label_encoder.inverse_transform(y_pred_test_lgb)\n",
        "#create the submission dataframe of desired format\n",
        "submission_lgb_new = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "#fill in the predictions made in the submission file\n",
        "submission_lgb_new['ID'] = [i+1 for i in range(len(y_pred_test_lgb_decoded))]\n",
        "submission_lgb_new['Crime_Category'] = y_pred_test_lgb_decoded\n",
        "#create a csv file for submission\n",
        "submission_lgb_new.to_csv('submission_lgb_new.csv',index=False)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fac3ccb",
      "metadata": {
        "papermill": {
          "duration": 0.022707,
          "end_time": "2024-08-08T08:15:27.714612",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.691905",
          "status": "completed"
        },
        "tags": [],
        "id": "7fac3ccb"
      },
      "source": [
        "<h2 style=\"color:purple;\">Stacking Classifier</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38c607b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.762013Z",
          "iopub.status.busy": "2024-08-08T08:15:27.761621Z",
          "iopub.status.idle": "2024-08-08T08:15:27.769877Z",
          "shell.execute_reply": "2024-08-08T08:15:27.768456Z"
        },
        "papermill": {
          "duration": 0.035023,
          "end_time": "2024-08-08T08:15:27.772519",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.737496",
          "status": "completed"
        },
        "tags": [],
        "id": "f38c607b",
        "outputId": "d5619f5a-eec9-41f0-af2c-258d2aa0478e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Initialize base models with the best parameters\\nxgb_model = xgb.XGBClassifier( random_state=42, colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9 )\\nlgb_model = lgb.LGBMClassifier(random_state=42, colsample_bytree=0.7110049608671793, learning_rate=0.06048738886880416, max_depth=9, min_data_in_leaf=12, min_gain_to_split=0.17904136753743988, n_estimators=337, num_leaves=370, subsample=0.8596340455795947)\\nrf_model = RandomForestClassifier( random_state=42, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 )\\n\\n# Initialize Stacking Classifier with Logistic Regression as the meta-learner\\nstacking_model = StackingClassifier(\\n    estimators=[\\n        (\\'xgb\\', xgb_model),\\n        (\\'lgb\\', lgb_model),\\n        (\\'rf\\', rf_model)\\n    ],\\n    final_estimator=LogisticRegression()\\n)\\n# Fit the stacking model\\nstacking_model.fit(X_train, y_train_encoded)\\n# Make predictions on the validation set\\ny_pred_val_stacking = stacking_model.predict(X_val)\\n# Decode the predictions back to original labels\\ny_pred_val_stacking_decoded = label_encoder.inverse_transform(y_pred_val_stacking)\\n# Calculate accuracy on the validation set\\naccuracy_val_stacking = accuracy_score(y_val, y_pred_val_stacking_decoded)\\nprint(f\"Stacking Model Validation Accuracy: {accuracy_val_stacking}\")\\n#Accuracy Score on Validation Set is : 0.85775\\n\\n#other metrics to understand performance\\n# Precision\\nprecision_stack = precision_score(y_val, y_pred_val_stacking_decoded, average=\\'weighted\\')\\nprint(f\"Precision: {precision_stack:.4f}\")\\n\\n# Recall\\nrecall_stack = recall_score(y_val, y_pred_val_stacking_decoded, average=\\'weighted\\')\\nprint(f\"Recall: {recall_stack:.4f}\")\\n\\n# F1 Score\\nf1_stack = f1_score(y_val, y_pred_val_stacking_decoded, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_stack:.4f}\")\\n#Precision: 0.8722 Recall: 0.8602 F1 Score: 0.8578\\n'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Initialize base models with the best parameters\n",
        "xgb_model = xgb.XGBClassifier( random_state=42, colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9 )\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42, colsample_bytree=0.7110049608671793, learning_rate=0.06048738886880416, max_depth=9, min_data_in_leaf=12, min_gain_to_split=0.17904136753743988, n_estimators=337, num_leaves=370, subsample=0.8596340455795947)\n",
        "rf_model = RandomForestClassifier( random_state=42, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 )\n",
        "\n",
        "# Initialize Stacking Classifier with Logistic Regression as the meta-learner\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('rf', rf_model)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression()\n",
        ")\n",
        "# Fit the stacking model\n",
        "stacking_model.fit(X_train, y_train_encoded)\n",
        "# Make predictions on the validation set\n",
        "y_pred_val_stacking = stacking_model.predict(X_val)\n",
        "# Decode the predictions back to original labels\n",
        "y_pred_val_stacking_decoded = label_encoder.inverse_transform(y_pred_val_stacking)\n",
        "# Calculate accuracy on the validation set\n",
        "accuracy_val_stacking = accuracy_score(y_val, y_pred_val_stacking_decoded)\n",
        "print(f\"Stacking Model Validation Accuracy: {accuracy_val_stacking}\")\n",
        "#Accuracy Score on Validation Set is : 0.85775\n",
        "\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_stack = precision_score(y_val, y_pred_val_stacking_decoded, average='weighted')\n",
        "print(f\"Precision: {precision_stack:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_stack = recall_score(y_val, y_pred_val_stacking_decoded, average='weighted')\n",
        "print(f\"Recall: {recall_stack:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_stack = f1_score(y_val, y_pred_val_stacking_decoded, average='weighted')\n",
        "print(f\"F1 Score: {f1_stack:.4f}\")\n",
        "#Precision: 0.8722 Recall: 0.8602 F1 Score: 0.8578\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a064064e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.821168Z",
          "iopub.status.busy": "2024-08-08T08:15:27.820022Z",
          "iopub.status.idle": "2024-08-08T08:15:27.827582Z",
          "shell.execute_reply": "2024-08-08T08:15:27.826406Z"
        },
        "papermill": {
          "duration": 0.034599,
          "end_time": "2024-08-08T08:15:27.829949",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.795350",
          "status": "completed"
        },
        "tags": [],
        "id": "a064064e",
        "outputId": "c7cdb849-5258-417c-efa6-987bfae8a7d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n#Make predictions on the test set\\ny_pred_test_stacking = stacking_model.predict(test_df)\\n#Decode the test predictions back to original labels\\ny_pred_test_decoded_stacking = label_encoder.inverse_transform(y_pred_test_stacking)\\n#create the submission dataframe of desired format\\nsubmission_stacking = pd.DataFrame(columns=['ID','Crime_Category'])\\n#fill in the predictions made in the submission file\\nsubmission_stacking['ID'] = [i+1 for i in range(len(y_pred_test_decoded_stacking))] \\nsubmission_stacking['Crime_Category'] = y_pred_test_decoded_stacking\\n#create a csv file for submission\\nsubmission_stacking.to_csv('submission_stacking.csv',index=False)\\n\""
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#Make predictions on the test set\n",
        "y_pred_test_stacking = stacking_model.predict(test_df)\n",
        "#Decode the test predictions back to original labels\n",
        "y_pred_test_decoded_stacking = label_encoder.inverse_transform(y_pred_test_stacking)\n",
        "#create the submission dataframe of desired format\n",
        "submission_stacking = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "#fill in the predictions made in the submission file\n",
        "submission_stacking['ID'] = [i+1 for i in range(len(y_pred_test_decoded_stacking))]\n",
        "submission_stacking['Crime_Category'] = y_pred_test_decoded_stacking\n",
        "#create a csv file for submission\n",
        "submission_stacking.to_csv('submission_stacking.csv',index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8606dd32",
      "metadata": {
        "papermill": {
          "duration": 0.022868,
          "end_time": "2024-08-08T08:15:27.876488",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.853620",
          "status": "completed"
        },
        "tags": [],
        "id": "8606dd32"
      },
      "source": [
        "<h2 style=\"color:purple;\">LGBM With OverSampling Using SMOTE</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21eb5a8f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.924228Z",
          "iopub.status.busy": "2024-08-08T08:15:27.923770Z",
          "iopub.status.idle": "2024-08-08T08:15:27.931851Z",
          "shell.execute_reply": "2024-08-08T08:15:27.930539Z"
        },
        "papermill": {
          "duration": 0.034946,
          "end_time": "2024-08-08T08:15:27.934389",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.899443",
          "status": "completed"
        },
        "tags": [],
        "id": "21eb5a8f",
        "outputId": "0405d8b5-fdaa-4657-aaff-23b4500709b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#best_params_lgb = { \\'colsample_bytree\\': 0.7110049608671793, \\'learning_rate\\': 0.06048738886880416, \\'max_depth\\': 9, \\'min_data_in_leaf\\': 12, \\'min_gain_to_split\\': 0.17904136753743988, \\'n_estimators\\': 337, \\'num_leaves\\': 370, \\'subsample\\': 0.8596340455795947 }\\nlgb_model = lgb.LGBMClassifier(random_state=42, class_weight=\\'balanced\\', \\n                                colsample_bytree=0.7110049608671793, \\n                                learning_rate=0.06048738886880416, \\n                                max_depth=9, \\n                                min_data_in_leaf=12, \\n                                min_gain_to_split=0.17904136753743988, \\n                                n_estimators=337, \\n                                num_leaves=370, \\n                                subsample=0.8596340455795947)\\n\\n# Apply SMOTE to the training data\\nsmote = SMOTE(random_state=42)\\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_encoded)\\nlgb_model.fit(X_train_resampled, y_train_resampled)\\ny_pred_val_lgb = lgb_model.predict(X_val)\\ny_pred_val_lgb_decoded = label_encoder.inverse_transform(y_pred_val_lgb)\\naccuracy_val_lgb = accuracy_score(y_val, y_pred_val_lgb_decoded)\\nprint(f\"LightGBM Validation Accuracy with Class Weight Adjustment: {accuracy_val_lgb}\")\\n#Accuracy Score on Validation Set is : 0.86\\n\\n#other metrics to understand performance\\n# Precision\\nprecision_smote = precision_score(y_val, y_pred_val_lgb_decoded, average=\\'weighted\\')\\nprint(f\"Precision: {precision_smote:.4f}\")\\n\\n# Recall\\nrecall_smote = recall_score(y_val, y_pred_val_lgb_decoded, average=\\'weighted\\')\\nprint(f\"Recall: {recall_smote:.4f}\")\\n\\n# F1 Score\\nf1_smote = f1_score(y_val, y_pred_val_lgb_decoded, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_smote:.4f}\")\\n#Precision: 0.8803 Recall: 0.8600 F1 Score: 0.8586\\n'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#best_params_lgb = { 'colsample_bytree': 0.7110049608671793, 'learning_rate': 0.06048738886880416, 'max_depth': 9, 'min_data_in_leaf': 12, 'min_gain_to_split': 0.17904136753743988, 'n_estimators': 337, 'num_leaves': 370, 'subsample': 0.8596340455795947 }\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42, class_weight='balanced',\n",
        "                                colsample_bytree=0.7110049608671793,\n",
        "                                learning_rate=0.06048738886880416,\n",
        "                                max_depth=9,\n",
        "                                min_data_in_leaf=12,\n",
        "                                min_gain_to_split=0.17904136753743988,\n",
        "                                n_estimators=337,\n",
        "                                num_leaves=370,\n",
        "                                subsample=0.8596340455795947)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_encoded)\n",
        "lgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_val_lgb = lgb_model.predict(X_val)\n",
        "y_pred_val_lgb_decoded = label_encoder.inverse_transform(y_pred_val_lgb)\n",
        "accuracy_val_lgb = accuracy_score(y_val, y_pred_val_lgb_decoded)\n",
        "print(f\"LightGBM Validation Accuracy with Class Weight Adjustment: {accuracy_val_lgb}\")\n",
        "#Accuracy Score on Validation Set is : 0.86\n",
        "\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_smote = precision_score(y_val, y_pred_val_lgb_decoded, average='weighted')\n",
        "print(f\"Precision: {precision_smote:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_smote = recall_score(y_val, y_pred_val_lgb_decoded, average='weighted')\n",
        "print(f\"Recall: {recall_smote:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_smote = f1_score(y_val, y_pred_val_lgb_decoded, average='weighted')\n",
        "print(f\"F1 Score: {f1_smote:.4f}\")\n",
        "#Precision: 0.8803 Recall: 0.8600 F1 Score: 0.8586\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7efb46",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:27.983469Z",
          "iopub.status.busy": "2024-08-08T08:15:27.983006Z",
          "iopub.status.idle": "2024-08-08T08:15:27.990074Z",
          "shell.execute_reply": "2024-08-08T08:15:27.988888Z"
        },
        "papermill": {
          "duration": 0.034653,
          "end_time": "2024-08-08T08:15:27.992474",
          "exception": false,
          "start_time": "2024-08-08T08:15:27.957821",
          "status": "completed"
        },
        "tags": [],
        "id": "6e7efb46",
        "outputId": "3c6c3b1a-6aa6-4d27-f002-3a63d0a18f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ny_pred_test = lgb_model.predict(test_df)\\ny_pred_test_lgb_decoded = label_encoder.inverse_transform(y_pred_test)\\nsubmission_lgb_smote = pd.DataFrame(columns=['ID','Crime_Category'])\\nsubmission_lgb_smote['ID'] = [i+1 for i in range(len(y_pred_test_lgb_decoded))] \\nsubmission_lgb_smote['Crime_Category'] = y_pred_test_lgb_decoded\\nsubmission_lgb_smote.to_csv('submission_lgb_smote.csv',index=False)\\n\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "y_pred_test = lgb_model.predict(test_df)\n",
        "y_pred_test_lgb_decoded = label_encoder.inverse_transform(y_pred_test)\n",
        "submission_lgb_smote = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "submission_lgb_smote['ID'] = [i+1 for i in range(len(y_pred_test_lgb_decoded))]\n",
        "submission_lgb_smote['Crime_Category'] = y_pred_test_lgb_decoded\n",
        "submission_lgb_smote.to_csv('submission_lgb_smote.csv',index=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38932977",
      "metadata": {
        "papermill": {
          "duration": 0.02427,
          "end_time": "2024-08-08T08:15:28.040119",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.015849",
          "status": "completed"
        },
        "tags": [],
        "id": "38932977"
      },
      "source": [
        "<h2 style=\"color:purple;\">Support Vector Machine</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81e4a8c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:28.090856Z",
          "iopub.status.busy": "2024-08-08T08:15:28.090449Z",
          "iopub.status.idle": "2024-08-08T08:15:28.097882Z",
          "shell.execute_reply": "2024-08-08T08:15:28.096753Z"
        },
        "papermill": {
          "duration": 0.034741,
          "end_time": "2024-08-08T08:15:28.100087",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.065346",
          "status": "completed"
        },
        "tags": [],
        "id": "f81e4a8c",
        "outputId": "15686e7e-9d28-487b-cc97-008d21c47b5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Define SVM with specified parameters\\nsvm_model_tuned = SVC(kernel=\\'rbf\\', C=1, gamma=\\'scale\\', random_state=42, class_weight=\\'balanced\\')\\n\\n# Fit the model on the original training data\\nsvm_model_tuned.fit(X_train, y_train_encoded)\\n\\n# Make predictions on the validation set\\ny_pred_val_svm_tuned = svm_model_tuned.predict(X_val)\\n\\n# Decode the predictions back to original labels\\ny_pred_val_svm_tuned_decoded = label_encoder.inverse_transform(y_pred_val_svm_tuned)\\n\\n# Calculate accuracy\\naccuracy_val_svm_tuned = accuracy_score(y_val, y_pred_val_svm_tuned_decoded)\\nprint(f\"SVM Validation Accuracy (Tuned): {accuracy_val_svm_tuned}\")\\n\\n#Accuracy Score on Validation set is : 0.5285\\n\\n#other metrics to understand performance\\n# Precision\\nprecision_svm = precision_score(y_val, y_pred_val_svm_tuned_decoded, average=\\'weighted\\')\\nprint(f\"Precision: {precision_svm:.4f}\")\\n\\n# Recall\\nrecall_svm = recall_score(y_val, y_pred_val_svm_tuned_decoded, average=\\'weighted\\')\\nprint(f\"Recall: {recall_svm:.4f}\")\\n\\n# F1 Score\\nf1_svm = f1_score(y_val, y_pred_val_svm_tuned_decoded, average=\\'weighted\\')\\nprint(f\"F1 Score: {f1_svm:.4f}\")\\n\\nPrecision: 0.5359 Recall: 0.5285 F1 Score: 0.4458\\n'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Define SVM with specified parameters\n",
        "svm_model_tuned = SVC(kernel='rbf', C=1, gamma='scale', random_state=42, class_weight='balanced')\n",
        "\n",
        "# Fit the model on the original training data\n",
        "svm_model_tuned.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred_val_svm_tuned = svm_model_tuned.predict(X_val)\n",
        "\n",
        "# Decode the predictions back to original labels\n",
        "y_pred_val_svm_tuned_decoded = label_encoder.inverse_transform(y_pred_val_svm_tuned)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_val_svm_tuned = accuracy_score(y_val, y_pred_val_svm_tuned_decoded)\n",
        "print(f\"SVM Validation Accuracy (Tuned): {accuracy_val_svm_tuned}\")\n",
        "\n",
        "#Accuracy Score on Validation set is : 0.5285\n",
        "\n",
        "#other metrics to understand performance\n",
        "# Precision\n",
        "precision_svm = precision_score(y_val, y_pred_val_svm_tuned_decoded, average='weighted')\n",
        "print(f\"Precision: {precision_svm:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall_svm = recall_score(y_val, y_pred_val_svm_tuned_decoded, average='weighted')\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_svm = f1_score(y_val, y_pred_val_svm_tuned_decoded, average='weighted')\n",
        "print(f\"F1 Score: {f1_svm:.4f}\")\n",
        "\n",
        "Precision: 0.5359 Recall: 0.5285 F1 Score: 0.4458\n",
        "'''\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537cad07",
      "metadata": {
        "papermill": {
          "duration": 0.023558,
          "end_time": "2024-08-08T08:15:28.146834",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.123276",
          "status": "completed"
        },
        "tags": [],
        "id": "537cad07"
      },
      "source": [
        "<h2 style=\"color:purple;\">Models Comparison</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d1dbfb",
      "metadata": {
        "papermill": {
          "duration": 0.024602,
          "end_time": "2024-08-08T08:15:28.195607",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.171005",
          "status": "completed"
        },
        "tags": [],
        "id": "c9d1dbfb"
      },
      "source": [
        "| **Model Name**                          | **Validation Accuracy** | **Test Accuracy** | **Precision** | **Recall** | **F1 Score** |\n",
        "|-----------------------------------------|-------------------------|-------------------|---------------|------------|--------------|\n",
        "| Dummy Classifier                        | 0.57575                 | 0.5866            | N/A           | N/A        | N/A          |\n",
        "| Logistic Regression Classifier          | 0.65325                 | 0.6728            | 0.6034        | 0.6532     | 0.5891       |\n",
        "| Logistic Regression With Polynomial Features | 0.74775                 | 0.6756            | 0.7393        | 0.7482     | 0.7265       |\n",
        "| KNN Classifier                          | 0.49725                 | 0.6728            | 0.7602        | 0.4973     | 0.5480       |\n",
        "| SVM                                     | 0.5285                  | 0.6728            | 0.5359        | 0.5285     | 0.4458       |\n",
        "| **Random Forest Classifier**            | **0.84825**             | **0.8462**        | **0.8514**    | **0.8482** | **0.8368**   |\n",
        "| **LGBM Classifier**                     | **0.85825**             | **0.8654**        | **0.8759**    | **0.8582** | **0.8566**   |\n",
        "| **XGBoost Classifier**                  | **0.86125**             | **0.8668**        | **0.8774**    | **0.8612** | **0.8600**   |\n",
        "| **Stacking Classifier**                 | **0.85775**             | **0.8562**        | **0.8722**    | **0.8602** | **0.8578**   |\n",
        "| **LGBM with SMOTE (Oversampling)**      | **0.86**                | **0.862**         | **0.8803**    | **0.8600** | **0.8586**   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d00f8f",
      "metadata": {
        "papermill": {
          "duration": 0.023481,
          "end_time": "2024-08-08T08:15:28.243068",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.219587",
          "status": "completed"
        },
        "tags": [],
        "id": "60d00f8f"
      },
      "source": [
        "### Insights into Model Performances\n",
        "\n",
        "1. **Logistic Regression Classifier**:\n",
        "   - **Accuracy**: Achieved a validation accuracy of 0.65325 and test accuracy of 0.6728.\n",
        "   - **Precision**: 0.6034\n",
        "   - **Recall**: 0.6532\n",
        "   - **F1 Score**: 0.5891\n",
        "   - **Insight**: This model shows a balanced performance but falls short in precision and F1 score, indicating that it may struggle with correctly classifying positive instances.\n",
        "\n",
        "2. **Logistic Regression with Polynomial Features**:\n",
        "   - **Accuracy**: Improved validation accuracy to 0.74775, but test accuracy is 0.6756.\n",
        "   - **Precision**: 0.7393\n",
        "   - **Recall**: 0.7482\n",
        "   - **F1 Score**: 0.7265\n",
        "   - **Insight**: Polynomial features increased the complexity and performance on the validation set, but the test set performance did not improve significantly, suggesting potential overfitting.\n",
        "\n",
        "3. **KNN Classifier**:\n",
        "   - **Accuracy**: Validation accuracy of 0.49725 and test accuracy of 0.6728.\n",
        "   - **Precision**: 0.7602\n",
        "   - **Recall**: 0.4973\n",
        "   - **F1 Score**: 0.5480\n",
        "   - **Insight**: The KNN classifier shows high precision but low recall, indicating it is conservative in predicting positive instances but does so with high accuracy when it does.\n",
        "\n",
        "4. **SVM**:\n",
        "   - **Accuracy**: Validation accuracy of 0.5285 and test accuracy of 0.6728.\n",
        "   - **Precision**: 0.5359\n",
        "   - **Recall**: 0.5285\n",
        "   - **F1 Score**: 0.4458\n",
        "   - **Insight**: The SVM model struggles with this dataset, reflected by its lower precision, recall, and F1 score.\n",
        "\n",
        "5. **Random Forest Classifier**:\n",
        "   - **Accuracy**: Validation accuracy of 0.84825 and test accuracy of 0.8462.\n",
        "   - **Precision**: 0.8514\n",
        "   - **Recall**: 0.8482\n",
        "   - **F1 Score**: 0.8368\n",
        "   - **Insight**: The Random Forest model performs well with high accuracy, precision, recall, and F1 score, making it a strong candidate for this classification task.\n",
        "\n",
        "6. **LGBM Classifier**:\n",
        "   - **Accuracy**: Validation accuracy of 0.85825 and test accuracy of 0.8654.\n",
        "   - **Precision**: 0.8759\n",
        "   - **Recall**: 0.8582\n",
        "   - **F1 Score**: 0.8566\n",
        "   - **Insight**: LightGBM shows excellent performance across all metrics, particularly high precision and F1 score, indicating robust model performance.\n",
        "\n",
        "7. **XGBoost Classifier**:\n",
        "   - **Accuracy**: Validation accuracy of 0.86125 and test accuracy of 0.8668.\n",
        "   - **Precision**: 0.8774\n",
        "   - **Recall**: 0.8612\n",
        "   - **F1 Score**: 0.8600\n",
        "   - **Insight**: XGBoost provides the best test accuracy, precision, recall, and F1 score, making it the top-performing model for this dataset.\n",
        "\n",
        "8. **Stacking Classifier**:\n",
        "   - **Accuracy**: Validation accuracy of 0.85775 and test accuracy of 0.8562.\n",
        "   - **Precision**: 0.8722\n",
        "   - **Recall**: 0.8602\n",
        "   - **F1 Score**: 0.8578\n",
        "   - **Insight**: The stacking classifier performs similarly to XGBoost and LightGBM, indicating that an ensemble of models can achieve competitive performance.\n",
        "\n",
        "9. **LGBM with SMOTE (Oversampling)**:\n",
        "   - **Accuracy**: Validation accuracy of 0.86 and test accuracy of 0.862.\n",
        "   - **Precision**: 0.8803\n",
        "   - **Recall**: 0.8600\n",
        "   - **F1 Score**: 0.8586\n",
        "   - **Insight**: Using SMOTE with LightGBM improves the precision slightly, though overall performance remains similar to other top models. This suggests handling class imbalance can marginally benefit the model.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The XGBoost Classifier emerges as the best-performing model based on test accuracy and overall balanced performance across precision, recall, and F1 score. Models like LightGBM and Random Forest also perform very well, showing the effectiveness of ensemble methods for this classification task. Using techniques like SMOTE for handling class imbalance further refines the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ca07a1",
      "metadata": {
        "papermill": {
          "duration": 0.023694,
          "end_time": "2024-08-08T08:15:28.290649",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.266955",
          "status": "completed"
        },
        "tags": [],
        "id": "76ca07a1"
      },
      "source": [
        "**As concluded XGBoost Classifier is the best performer, so let's train the model with full data for submission with all the preprocessing steps**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b6c7ad9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:28.339844Z",
          "iopub.status.busy": "2024-08-08T08:15:28.339426Z",
          "iopub.status.idle": "2024-08-08T08:15:39.444738Z",
          "shell.execute_reply": "2024-08-08T08:15:39.443663Z"
        },
        "papermill": {
          "duration": 11.133212,
          "end_time": "2024-08-08T08:15:39.447593",
          "exception": false,
          "start_time": "2024-08-08T08:15:28.314381",
          "status": "completed"
        },
        "tags": [],
        "id": "7b6c7ad9"
      },
      "outputs": [],
      "source": [
        "# Impute missing values for numerical columns\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "train_df[numerical_cols] = num_imputer.fit_transform(train_df[numerical_cols])\n",
        "test_df[numerical_cols] = num_imputer.transform(test_df[numerical_cols])\n",
        "\n",
        "# Impute missing values for categorical columns\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "train_df[categorical_cols] = cat_imputer.fit_transform(train_df[categorical_cols])\n",
        "test_df[categorical_cols] = cat_imputer.transform(test_df[categorical_cols])\n",
        "\n",
        "# Function for frequency encoding\n",
        "def frequency_encoding_final(column, df, df_test=None):\n",
        "    freq_encoding = df[column].value_counts() / len(df)\n",
        "    df[column + '_freq'] = df[column].map(freq_encoding)\n",
        "    if df_test is not None:\n",
        "        df_test[column + '_freq'] = df_test[column].map(freq_encoding).fillna(0)\n",
        "    return df, df_test\n",
        "\n",
        "# Define high cardinality and ordinal encoder columns\n",
        "high_cardinality_cols = ['Location', 'Cross_Street', 'Modus_Operandi', 'Premise_Description', 'Weapon_Description']\n",
        "ordinal_encoder_cols = ['Area_Name', 'Part1-2', 'Victim_Sex', 'Victim_Descent', 'Status', 'Status_Description']\n",
        "\n",
        "# Apply Frequency Encoding for high cardinality columns\n",
        "for col in high_cardinality_cols:\n",
        "    train_df, test_df = frequency_encoding_final(col, train_df, test_df)\n",
        "\n",
        "# Apply Ordinal Encoder for other categorical columns\n",
        "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_df[ordinal_encoder_cols] = oe.fit_transform(train_df[ordinal_encoder_cols])\n",
        "test_df[ordinal_encoder_cols] = oe.transform(test_df[ordinal_encoder_cols])\n",
        "\n",
        "# Drop the original high cardinality columns as we have their frequency encoded versions\n",
        "train_df = train_df.drop(columns=high_cardinality_cols)\n",
        "test_df = test_df.drop(columns=high_cardinality_cols)\n",
        "\n",
        "# Separate features and target\n",
        "X_train_full = train_df.drop(columns='Crime_Category')\n",
        "y_train_full = train_df['Crime_Category']\n",
        "\n",
        "# Use SimpleImputer to fill any remaining missing values (if any) - only for X_train_full and X_test\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train_full = pd.DataFrame(imputer.fit_transform(X_train_full), columns=X_train_full.columns)\n",
        "test_df = pd.DataFrame(imputer.transform(test_df), columns=test_df.columns)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_full[numerical_cols] = scaler.fit_transform(X_train_full[numerical_cols])\n",
        "test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_full = label_encoder.fit_transform(y_train_full)\n",
        "\n",
        "# Initialize the LightGBM classifier with best parameters\n",
        "best_params_lgb_final = {\n",
        "    'colsample_bytree': 0.7110049608671793,\n",
        "    'learning_rate': 0.06048738886880416,\n",
        "    'max_depth': 9,\n",
        "    'min_data_in_leaf': 12,\n",
        "    'min_gain_to_split': 0.17904136753743988,\n",
        "    'n_estimators': 337,\n",
        "    'num_leaves': 370,\n",
        "    'subsample': 0.8596340455795947\n",
        "}\n",
        "best_lgb_model_final = lgb.LGBMClassifier(random_state=42, **best_params_lgb_final,verbose=-1)\n",
        "best_lgb_model_final.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_test_final = best_lgb_model_final.predict(test_df)\n",
        "y_pred_test_decoded_final = label_encoder.inverse_transform(y_pred_test_final)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be11d740",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-08T08:15:39.495971Z",
          "iopub.status.busy": "2024-08-08T08:15:39.495586Z",
          "iopub.status.idle": "2024-08-08T08:15:39.516987Z",
          "shell.execute_reply": "2024-08-08T08:15:39.515682Z"
        },
        "papermill": {
          "duration": 0.048836,
          "end_time": "2024-08-08T08:15:39.519689",
          "exception": false,
          "start_time": "2024-08-08T08:15:39.470853",
          "status": "completed"
        },
        "tags": [],
        "id": "be11d740"
      },
      "outputs": [],
      "source": [
        "\n",
        "submission_lgb_final = pd.DataFrame(columns=['ID','Crime_Category'])\n",
        "submission_lgb_final['ID'] = [i+1 for i in range(len(y_pred_test_decoded_final))]\n",
        "submission_lgb_final['Crime_Category'] = y_pred_test_decoded_final\n",
        "submission_lgb_final.to_csv('submission_lgb_final.csv',index=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 8446444,
          "sourceId": 77420,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30732,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 24.422098,
      "end_time": "2024-08-08T08:15:40.364999",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-08-08T08:15:15.942901",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}